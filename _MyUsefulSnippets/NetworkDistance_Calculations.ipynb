{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sporting-functionality",
   "metadata": {},
   "source": [
    "# How to calculate network distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conventional-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multidimvis_main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#\n",
    "# H U M A N \n",
    "#\n",
    "################################################\n",
    "\n",
    "organism = 'Human'\n",
    "\n",
    "G = nx.read_edgelist('input/ppi_elist.txt',data=False)\n",
    "# d_ent_sym, d_sym_ent = genent2sym()\n",
    "\n",
    "d_gene_do = pickle.load( open( \"input/d_gene_do.pkl\", \"rb\" ) )\n",
    "d_do_genes = pickle.load( open( \"input/d_do_genes.pkl\", \"rb\" ) )\n",
    "d_do_names = pickle.load( open( \"input/DO_names.pkl\", \"rb\" ) )\n",
    "d_names_do = {y:x for x,y in d_do_names.items()}\n",
    "    \n",
    "# Gene Symbols \n",
    "df_gene_sym = pd.read_csv('_output_csv/DF_gene_symbol_Human.csv', index_col=0)\n",
    "sym = list(df_gene_sym['0'])\n",
    "l_features = []\n",
    "for i in sym:\n",
    "    l_features.append(i[2:-2])\n",
    "d_gene_sym = dict(zip(G.nodes(),l_features))\n",
    "\n",
    "\n",
    "# ESSENTIALITY \n",
    "# get dataframe with ENSG-ID and essentiality state \n",
    "df_human_ess = pd.read_table('input/human_essentiality.txt', delim_whitespace=True)\n",
    "\n",
    "# create dict with ENSG-ID:essentiality state \n",
    "ensg_id = list(set(df_human_ess['sciName']))\n",
    "gene_ess = list(df_human_ess['locus'])\n",
    "d_ensg_ess = dict(zip(ensg_id, gene_ess))\n",
    " \n",
    "# match ENSG-ID with entrezID\n",
    "# \"engs_to_entrezid\": entrezIDs were matched with \"ensg_id.txt\" via \"DAVID Database\" (https://david.ncifcrf.gov/conversion.jsp)\n",
    "df_human_ensg_entrez = pd.read_table('input/ensg_to_entrezid.txt')# delim_whitespace=False)\n",
    "df_human_ensg_entrez.dropna()\n",
    "\n",
    "df = df_human_ensg_entrez\n",
    "df['To'] = df['To'].fillna(0)\n",
    "df['To'] = df['To'].astype(int)\n",
    "df_human_ensg_entrez = df\n",
    "\n",
    "# create dict with ENGS-ID: entrezID\n",
    "ensgid = list(df_human_ensg_entrez['From']) #engs ID\n",
    "entrezid = list(df_human_ensg_entrez['To']) #entrez ID \n",
    "\n",
    "# dict with engsid : entrezid\n",
    "d_ensg_entrez = dict(zip(ensgid, entrezid))\n",
    "\n",
    "# create dict with entrezID:essentiality state \n",
    "d_id_ess_unsorted = {}\n",
    "for ens,ent in d_ensg_entrez.items():\n",
    "    for en, ess in d_ensg_ess.items():\n",
    "        if ens == en:\n",
    "            d_id_ess_unsorted[str(ent)] = ess\n",
    "            \n",
    "            \n",
    "# check if G.nodes match entrezID in dict and sort according to G.nodes \n",
    "d_gid_ess = {}\n",
    "for k,v in d_id_ess_unsorted.items():\n",
    "    if k in G.nodes():\n",
    "        d_gid_ess[k]=v\n",
    "        \n",
    "# create dict with rest of G.nodes not in dict (entrezID:essentiality)\n",
    "d_gid_rest = {}\n",
    "for g in G.nodes():\n",
    "    if g not in d_gid_ess.keys():\n",
    "        d_gid_rest[g]='not defined'\n",
    "        \n",
    "#print(len(d_gid_rest)+len(d_gid_ess)) # this should match G.nodes count \n",
    "\n",
    "# merge both dicts\n",
    "d_gid_ess_all_unsorted = {**d_gid_ess, **d_gid_rest}\n",
    "\n",
    "# sort -> G.nodes()\n",
    "d_gID_all = {key:d_gid_ess_all_unsorted[key] for key in G.nodes()}\n",
    "\n",
    "essential_genes = []\n",
    "non_ess_genes = []\n",
    "notdefined_genes = [] \n",
    "for k,v in d_gID_all.items():\n",
    "    if v == 'E':\n",
    "        essential_genes.append(k)\n",
    "    elif v == 'NE':\n",
    "        non_ess_genes.append(k)\n",
    "    else:\n",
    "        notdefined_genes.append(k)\n",
    "        \n",
    "        \n",
    "# Centrality features \n",
    "df_centralities = pd.read_csv('_output_csv/Features_centralities_Dataframe_'+organism+'.csv', index_col=0)\n",
    "\n",
    "d_deghubs = dict(zip(G.nodes(), df_centralities['degs']))\n",
    "d_clos = dict(zip(G.nodes(), df_centralities['clos']))\n",
    "d_betw = dict(zip(G.nodes(), df_centralities['betw']))\n",
    "d_eigen = dict(zip(G.nodes(), df_centralities['eigen']))\n",
    "\n",
    "d_centralities = dict(zip(list(G.nodes),zip(d_deghubs.values(),d_clos.values(),d_betw.values(),d_eigen.values())))\n",
    "\n",
    "cent_features = []\n",
    "for i in d_centralities.items():\n",
    "    k=list(i)\n",
    "    cent_features.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "declared-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#\n",
    "# Y E A S T \n",
    "#\n",
    "################################################\n",
    "\n",
    "organism = 'Yeast'\n",
    "\n",
    "data = pickle.load( open( \"input/BIOGRID-ORGANISM-Saccharomyces_cerevisiae_S288c-3.5.185.mitab.pickle\", \"rb\" ) )\n",
    "\n",
    "filter_score = data[\n",
    "                    #(data['Interaction Types'] == 'psi-mi:\"MI:0915\"(physical association)') +\n",
    "                    (data['Interaction Types'] == 'psi-mi:\"MI:0407\"(direct interaction)') \n",
    "                    #&\n",
    "                    #(data['Taxid Interactor A'] == \"taxid:559292\") & \n",
    "                    #(data['Taxid Interactor B'] == \"taxid:559292\") \n",
    "]\n",
    "\n",
    "g = nx.from_pandas_edgelist(filter_score, '#ID Interactor A', 'ID Interactor B')\n",
    "g.remove_edges_from(nx.selfloop_edges(g)) #remove self loop\n",
    "\n",
    "G_cere = g.subgraph(max(nx.connected_components(g), key=len)) # largest connected component (lcc)\n",
    "G = G_cere\n",
    "\n",
    "posG_entrez = []\n",
    "for k in G.nodes():\n",
    "    posG_entrez.append(k[22:])\n",
    "    \n",
    "df_gID_sym = pd.read_csv('input/Yeast_geneID_sym.csv', index_col=0)\n",
    "gene_sym = list(df_gID_sym['Sym'])\n",
    "gene_id = list(df_gID_sym.index)\n",
    "g_ID_sym = dict(list(zip(gene_id, gene_sym)))\n",
    "#len(g_ID_sym)\n",
    "    \n",
    "l_features = []\n",
    "for i in g_ID_sym.values():\n",
    "    l_features.append(i)\n",
    "    \n",
    "# ESSENTIALITY \n",
    "\n",
    "cere_gene =pd.read_csv(\"input/Saccharomyces cerevisiae.csv\",\n",
    "           delimiter= ',',\n",
    "           skipinitialspace=True)\n",
    " \n",
    "cere_sym = list(cere_gene['symbols'])\n",
    "cere_ess = list(cere_gene['essentiality status'])\n",
    "cere_sym_essentiality = dict(zip(cere_sym, cere_ess))\n",
    "\n",
    "d_cere_ess = {}\n",
    "d_cere_noess = {}\n",
    "d_cere_unknown = {}\n",
    "\n",
    "for node,es in cere_sym_essentiality.items():\n",
    "    if es == 'E':\n",
    "        d_cere_ess[node]=es\n",
    "    elif es == 'NE':\n",
    "        d_cere_noess[node]=es\n",
    "        \n",
    "d_cere_alless = {}\n",
    "for nid, sym in g_ID_sym.items():\n",
    "    for sy,ess in cere_sym_essentiality.items():\n",
    "        if sym == sy:\n",
    "            d_cere_alless[nid] = ess\n",
    "            \n",
    "d_cere_unknown = {} \n",
    "for g in G.nodes():\n",
    "    if g not in d_cere_alless.keys():\n",
    "        d_cere_unknown[g]='status unkonwn'\n",
    "    \n",
    "d_geneID_ess = {**d_cere_unknown, **d_cere_alless}\n",
    "\n",
    "d_gID_ess = {}\n",
    "d_gID_noess = {}\n",
    "d_gID_notdef = {}\n",
    "\n",
    "for k,i in d_geneID_ess.items():\n",
    "    if i == 'E':\n",
    "        d_gID_ess[k] = i\n",
    "    elif i == 'NE':\n",
    "        d_gID_noess[k] = i\n",
    "    else: \n",
    "        d_gID_notdef[k] = 'not defined'\n",
    "\n",
    "d_gID_all_unsorted = {**d_gID_ess, **d_gID_noess, **d_gID_notdef}\n",
    "d_gID_all = {key:d_gID_all_unsorted[key] for key in G.nodes()}\n",
    "\n",
    "essential_genes = []\n",
    "non_ess_genes = []\n",
    "notdefined_genes = [] \n",
    "for k,v in d_gID_all.items():\n",
    "    if v == 'E':\n",
    "        essential_genes.append(k)\n",
    "    elif v == 'NE':\n",
    "        non_ess_genes.append(k)\n",
    "    else:\n",
    "        notdefined_genes.append(k)\n",
    "        \n",
    "# Centrality features \n",
    "df_centralities = pd.read_csv('_output_csv/Features_centralities_Dataframe_'+organism+'.csv', index_col=0)\n",
    "\n",
    "d_deghubs = dict(zip(G.nodes(), df_centralities['degs']))\n",
    "d_clos = dict(zip(G.nodes(), df_centralities['clos']))\n",
    "d_betw = dict(zip(G.nodes(), df_centralities['betw']))\n",
    "d_eigen = dict(zip(G.nodes(), df_centralities['eigen']))\n",
    "\n",
    "d_centralities = dict(zip(list(G.nodes),zip(d_deghubs.values(),d_clos.values(),d_betw.values(),d_eigen.values())))\n",
    "\n",
    "cent_features = []\n",
    "for i in d_centralities.items():\n",
    "    k=list(i)\n",
    "    cent_features.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#\n",
    "#    SAMPLE SUP PPI NETWORK\n",
    "#\n",
    "#################################################################\n",
    "\n",
    "rand_set = rd.sample(G.nodes(),200)\n",
    "\n",
    "G_sub = nx.subgraph(G,rand_set)\n",
    "\n",
    "G_ = G_sub.subgraph(max(nx.connected_components(G_sub), key=len))  # extract lcc graph\n",
    "\n",
    "\n",
    "print(G_.number_of_nodes())\n",
    "print(G_.number_of_edges())\n",
    "\n",
    "# nx.write_edgelist(G,'subPPI_4testing.txt')\n",
    "G=G_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-fifty",
   "metadata": {},
   "source": [
    "### Network Distance method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "virgin-charlotte",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 24min 18s, sys: 4min 4s, total: 1h 28min 22s\n",
      "Wall time: 1h 28min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "d_idx_entz = {}\n",
    "cc = 0\n",
    "for entz in sorted(G.nodes()):\n",
    "    d_idx_entz[cc] = entz\n",
    "    cc += 1\n",
    "\n",
    "Mspl = np.zeros(len(list(G.nodes())))\n",
    "\n",
    "for n1 in range(len(list(G.nodes()))):\n",
    "    vec = []\n",
    "    for n2 in range(len(list(G.nodes()))):\n",
    "        geneA = d_idx_entz[n1]\n",
    "        geneB = d_idx_entz[n2]\n",
    "        try:\n",
    "            spl = nx.shortest_path_length(G,geneA,geneB)\n",
    "            vec.append(spl)\n",
    "        except nx.NetworkXNoPath:\n",
    "            print('no path')\n",
    "        \n",
    "    Mspl = np.vstack((Mspl,vec))\n",
    "Mspl = np.delete(Mspl, (0), axis=0)\n",
    "DM_spl = pd.DataFrame(Mspl, index = list(G.nodes()), columns = list(G.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataframe get a dict with all pairs and values \n",
    "\n",
    "d_DM_spl = DM_spl.to_dict()\n",
    "\n",
    "d_SPL_pairs = {}\n",
    "for k,d in d_DM_spl.items():\n",
    "    for n,v in d.items():\n",
    "        d_SPL_pairs[k,n]=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "typical-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_spl.to_csv(r'_output_csv/SPL_Dataframe_Yeast.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-singles",
   "metadata": {},
   "source": [
    "### Network Distance method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "sublime-maker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.29 ms, sys: 26 µs, total: 3.32 ms\n",
      "Wall time: 3.39 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# NETWORK DISTANCE\n",
    "\n",
    "dist_network2D = {}\n",
    "for a in nx.shortest_path_length(G):\n",
    "    for n,spl in a[1].items():\n",
    "        dist_network2D[(a[0],n)] = spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "african-delivery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dist_network2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-pulse",
   "metadata": {},
   "source": [
    "### Network distance precalculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "taken-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_spl_prec = pd.read_csv('_output_csv/SPL_Dataframe_'+organism+'.csv', index_col=0)\n",
    "DM_spl_prec.index = list(G.nodes())\n",
    "DM_spl_prec.columns = list(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "inclusive-weight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>66008</th>\n",
       "      <th>8473</th>\n",
       "      <th>2561</th>\n",
       "      <th>3759</th>\n",
       "      <th>22906</th>\n",
       "      <th>4928</th>\n",
       "      <th>1994</th>\n",
       "      <th>8481</th>\n",
       "      <th>81610</th>\n",
       "      <th>51361</th>\n",
       "      <th>...</th>\n",
       "      <th>10838</th>\n",
       "      <th>8001</th>\n",
       "      <th>51351</th>\n",
       "      <th>1551</th>\n",
       "      <th>51458</th>\n",
       "      <th>143903</th>\n",
       "      <th>10861</th>\n",
       "      <th>51471</th>\n",
       "      <th>221044</th>\n",
       "      <th>29965</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66008</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8473</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22906</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143903</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10861</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51471</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221044</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29965</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16376 rows × 16376 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        66008  8473  2561  3759  22906  4928  1994  8481  81610  51361  ...  \\\n",
       "66008     0.0   3.0   3.0   3.0    3.0   3.0   3.0   4.0    3.0    4.0  ...   \n",
       "8473      3.0   0.0   3.0   2.0    3.0   3.0   3.0   3.0    3.0    4.0  ...   \n",
       "2561      3.0   3.0   0.0   3.0    3.0   3.0   2.0   4.0    3.0    4.0  ...   \n",
       "3759      3.0   2.0   3.0   0.0    3.0   2.0   3.0   3.0    3.0    4.0  ...   \n",
       "22906     3.0   3.0   3.0   3.0    0.0   3.0   3.0   4.0    3.0    4.0  ...   \n",
       "...       ...   ...   ...   ...    ...   ...   ...   ...    ...    ...  ...   \n",
       "143903    3.0   2.0   2.0   1.0    2.0   2.0   2.0   3.0    2.0    4.0  ...   \n",
       "10861     3.0   4.0   3.0   3.0    3.0   3.0   4.0   4.0    4.0    5.0  ...   \n",
       "51471     3.0   3.0   3.0   2.0    3.0   3.0   3.0   4.0    3.0    5.0  ...   \n",
       "221044    3.0   3.0   3.0   3.0    3.0   2.0   2.0   4.0    3.0    4.0  ...   \n",
       "29965     3.0   2.0   3.0   2.0    3.0   3.0   3.0   3.0    3.0    4.0  ...   \n",
       "\n",
       "        10838  8001  51351  1551  51458  143903  10861  51471  221044  29965  \n",
       "66008     3.0   3.0    3.0   2.0    3.0     3.0    3.0    3.0     3.0    3.0  \n",
       "8473      3.0   3.0    3.0   1.0    3.0     2.0    4.0    3.0     3.0    2.0  \n",
       "2561      2.0   3.0    3.0   2.0    3.0     2.0    3.0    3.0     3.0    3.0  \n",
       "3759      2.0   3.0    2.0   2.0    3.0     1.0    3.0    2.0     3.0    2.0  \n",
       "22906     2.0   3.0    3.0   2.0    3.0     2.0    3.0    3.0     3.0    3.0  \n",
       "...       ...   ...    ...   ...    ...     ...    ...    ...     ...    ...  \n",
       "143903    2.0   2.0    2.0   2.0    3.0     0.0    3.0    3.0     2.0    2.0  \n",
       "10861     3.0   4.0    3.0   3.0    4.0     3.0    0.0    4.0     3.0    3.0  \n",
       "51471     2.0   3.0    3.0   3.0    3.0     3.0    4.0    0.0     3.0    3.0  \n",
       "221044    2.0   3.0    2.0   2.0    3.0     2.0    3.0    3.0     0.0    3.0  \n",
       "29965     2.0   2.0    3.0   2.0    3.0     2.0    3.0    3.0     3.0    0.0  \n",
       "\n",
       "[16376 rows x 16376 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DM_spl_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "shaped-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataframe get a dict with all pairs and values \n",
    "\n",
    "d_DM_spl = DM_spl_prec.to_dict()\n",
    "\n",
    "d_SPL_pairs = {}\n",
    "for k,d in d_DM_spl.items():\n",
    "    for n,v in d.items():\n",
    "        d_SPL_pairs[k,n]=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-drove",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-nature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-sharing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-badge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
