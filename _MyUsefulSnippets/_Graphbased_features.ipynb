{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multidimvis_main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human \n",
    "G = nx.read_edgelist('input/ppi_elist.txt',data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeast \n",
    "data = pickle.load( open( \"input/BIOGRID-ORGANISM-Saccharomyces_cerevisiae_S288c-3.5.185.mitab.pickle\", \"rb\" ) )\n",
    "\n",
    "Counter(data['Interaction Detection Method'])\n",
    "Counter(data['Interaction Types'])\n",
    "\n",
    "filter_score = data[\n",
    "                    #(data['Interaction Types'] == 'psi-mi:\"MI:0915\"(physical association)') +\n",
    "                    (data['Interaction Types'] == 'psi-mi:\"MI:0407\"(direct interaction)') \n",
    "                    #&\n",
    "                    #(data['Taxid Interactor A'] == \"taxid:559292\") & \n",
    "                    #(data['Taxid Interactor B'] == \"taxid:559292\") \n",
    "]\n",
    "\n",
    "g = nx.from_pandas_edgelist(filter_score, '#ID Interactor A', 'ID Interactor B')\n",
    "g.remove_edges_from(nx.selfloop_edges(g)) #remove self loop\n",
    "\n",
    "G_cere = g.subgraph(max(nx.connected_components(g), key=len)) # largest connected component (lcc)\n",
    "\n",
    "# ESSENTIAL GENES \n",
    "cere_gene =pd.read_csv(\"input/Saccharomyces cerevisiae.csv\",\n",
    "           delimiter= ',',\n",
    "           skipinitialspace=True)\n",
    "essential_cere = cere_gene[(cere_gene['essentiality status'] == 'E')]\n",
    "essential_genes_cere_list =  essential_cere['symbols'].tolist()\n",
    "\n",
    "degree= dict(G_cere.degree())\n",
    "\n",
    "mg = mygene.MyGeneInfo()\n",
    "a = mg.querymany(essential_genes_cere_list, scopes='symbol', species=559292)\n",
    "essential_genes_cere_names = pd.DataFrame.from_dict(a)\n",
    "essential_genes_cere_entrez =  essential_genes_cere_names['entrezgene'].tolist()\n",
    "\n",
    "cleaned_entrez_list = [x for x in essential_genes_cere_entrez if str(x) != 'nan']\n",
    "\n",
    "degree_formatted={}\n",
    "for k, v in degree.items():\n",
    "    degree_formatted[k.replace(\"entrez gene/locuslink:\",\"\")] = v\n",
    "    \n",
    "index= []\n",
    "essential = []\n",
    "for i in cleaned_entrez_list:\n",
    "    for (key, val) in degree_formatted.items():\n",
    "        if i==key:\n",
    "            index.append(key)\n",
    "            essential.append(val)  \n",
    "\n",
    "no_essential_cere = cere_gene[(cere_gene['essentiality status'] == 'NE')]\n",
    "no_essential_genes_cere_list =  no_essential_cere['symbols'].tolist()\n",
    "b = mg.querymany(no_essential_genes_cere_list, scopes='symbol', species=559292)\n",
    "no_essential_genes_cere_names = pd.DataFrame.from_dict(b)\n",
    "no_essential_genes_cere_entrez =  no_essential_genes_cere_names['entrezgene'].tolist()\n",
    "cleaned_entrez_list_no = [x for x in no_essential_genes_cere_entrez if str(x) != 'nan']\n",
    "\n",
    "index= []\n",
    "no_essential = []\n",
    "for i in cleaned_entrez_list_no:\n",
    "    for (key, val) in degree_formatted.items():\n",
    "        if i==key:\n",
    "            index.append(key)\n",
    "            no_essential.append(val)\n",
    "            \n",
    "#df_cere = pd.DataFrame({'essential': pd.Series(essential), 'no_essential': pd.Series(no_essential)})\n",
    "\n",
    "\n",
    "no_ess_id = no_essential_genes_cere_names['entrezgene']\n",
    "ess_id = essential_genes_cere_names['entrezgene']\n",
    "G = G_cere\n",
    "\n",
    "#edge_list = nx.write_edgelist(G, \"Yeast_edgelist_directinteractiononly.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAPH BASED MATRICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 s, sys: 181 ms, total: 1.18 s\n",
      "Wall time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "A = nx.adjacency_matrix(G)\n",
    "DM_adj = A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj = pd.DataFrame(DM_adj, columns = list(G.nodes()), index=list(G.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj.to_csv(r'output_csv/Adjacency_Dataframe_Human.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shortest Path Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "d_idx_entz = {}\n",
    "cc = 0\n",
    "for entz in sorted(G.nodes()):\n",
    "    d_idx_entz[cc] = entz\n",
    "    cc += 1\n",
    "\n",
    "Mspl = np.zeros(len(list(G.nodes())))\n",
    "\n",
    "for n1 in range(len(list(G.nodes()))):\n",
    "    vec = []\n",
    "    for n2 in range(len(list(G.nodes()))):\n",
    "        geneA = d_idx_entz[n1]\n",
    "        geneB = d_idx_entz[n2]\n",
    "        try:\n",
    "            spl = nx.shortest_path_length(G,geneA,geneB)\n",
    "            vec.append(spl)\n",
    "        except nx.NetworkXNoPath:\n",
    "            print('no path')\n",
    "        \n",
    "    Mspl = np.vstack((Mspl,vec))\n",
    "Mspl = np.delete(Mspl, (0), axis=0)\n",
    "\n",
    "DM_spl = Mspl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spl = pd.DataFrame(DM_spl, columns = list(G.nodes()), index=list(G.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spl.to_csv(r'output_csv/SPL_Dataframe_Human.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Markov: Random Walk with restart probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 15s, sys: 12.6 s, total: 6min 28s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Restart probability\n",
    "r = .8 # originally 0.8\n",
    "alpha = 1.0 # indicating \"randomness\" \n",
    "\n",
    "DM_m = rnd_walk_matrix2(A, r, alpha, len(G.nodes()))\n",
    "\n",
    "DM_m_df = pd.DataFrame(DM_m)\n",
    "# DM_m_df.sum(axis=0)\n",
    "\n",
    "DM_m_transposed = DM_m_df.T\n",
    "DM_m_transposed.index = list(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46min 38s, sys: 24.6 s, total: 47min 3s\n",
      "Wall time: 47min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "metric = \"cosine\" \n",
    "DM_m_new = pd.DataFrame(distance.squareform(distance.pdist(DM_m_transposed, metric)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = pd.DataFrame(DM_m_new, columns = list(G.nodes()), index=list(G.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.to_csv(r'output_csv/RWR_'+metric+'_Dataframe_Human.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -log Markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MARKOV / RWR - LOG\n",
    "\n",
    "#min_log = lambda t: -np.log(t)\n",
    "#DM_mlog = np.array([min_log(x/max(x)) for x in DM_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlog = pd.DataFrame(DM_mlog, columns = list(G.nodes()), index=list(G.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlog.to_csv(r'output_csv/RWR_log_'+metric+'_Dataframe_Human.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
