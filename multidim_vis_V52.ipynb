{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE OVERVIEW\n",
    "+ graph with genes as nodes and edges\n",
    "+ generate a matrix from nodes based on specific parameters (features, random walk, shortest path..)\n",
    "+ multidimensional matrices > embedding with tsne into 2D or 3D \n",
    "----------\n",
    "+ Visualization typologies:\n",
    "+ 2D PORTRAIT\n",
    "+ 3D PORTRAIT\n",
    "+ 3D LANDSCAPE\n",
    "+ 3D SPHERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import bezier\n",
    "\n",
    "from collections import (defaultdict,Counter)\n",
    "from collections import defaultdict as dd\n",
    "from collections import Counter as ct\n",
    "from collections import OrderedDict\n",
    "import colorsys\n",
    "from colormap import rgb2hex, rgb2hls, hls2rgb\n",
    "from colormath.color_objects import sRGBColor, LabColor\n",
    "from colormath.color_conversions import convert_color\n",
    "from colormath.color_diff import delta_e_cie2000\n",
    "from collections import Counter\n",
    "\n",
    "from dosnes import dosnes\n",
    "\n",
    "from fisher import pvalue\n",
    "from fa2 import ForceAtlas2\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "from matplotlib import colors as mcolors\n",
    "import math\n",
    "from math import *\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "import mygene\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms.flow import shortest_augmenting_path\n",
    "from networkx.generators.degree_seq import expected_degree_graph\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as pgo\n",
    "import plotly.offline as py\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.io as pio\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import pylab\n",
    "\n",
    "py.init_notebook_mode(connected = True)\n",
    "\n",
    "#import pymysql as mysql\n",
    "\n",
    "import random as rd\n",
    "\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import scipy.stats as st\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import scipy.spatial.distance as dist\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.interpolate import interpn\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection,cluster)\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import sys \n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import umap "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------\n",
    "\n",
    "# SECTION FOR FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSIS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha potentiell raus ?\n",
    "# page rank methode\n",
    "def rnd_walk_matrix2(A, r, a, num_nodes):\n",
    "\n",
    "    num = 1*num_nodes\n",
    "    n = num_nodes\n",
    "    factor = float((1-a)/n)\n",
    "\n",
    "    E = np.multiply(factor,np.ones([n,n]))              # prepare 2nd scaling term\n",
    "    A_tele = np.multiply(a,A) + E  #     print(A_tele)\n",
    "    M = normalize(A_tele, norm='l1', axis=0)                                 # column wise normalized MArkov matrix\n",
    "\n",
    "    # mixture of Markov chains\n",
    "    del A_tele\n",
    "    del E\n",
    "\n",
    "    U = np.identity(n,dtype=int) \n",
    "    H = (1-r)*M\n",
    "    H1 = np.subtract(U,H)\n",
    "    del U\n",
    "    del M\n",
    "    del H    \n",
    "\n",
    "    W = r*np.linalg.inv(H1)   \n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOTTING FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Heatmap + Cluster from Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generate a heatmap + Dendogramm from a Matrix.\n",
    "Return plot.\n",
    "'''\n",
    "def heatmap_from_matrix(Matrix, title = None):\n",
    "\n",
    "    # Dendogramm\n",
    "    fig = pylab.figure(figsize=(12,8))\n",
    "\n",
    "    axdendro = fig.add_axes([0.09,0.1,0.2,0.8])\n",
    "    Y = sch.linkage(Matrix, method='average')\n",
    "    Z = sch.dendrogram(Y, orientation='left')\n",
    "    axdendro.set_xticks([])\n",
    "    axdendro.set_yticks([])\n",
    "\n",
    "\n",
    "    # Plot distance \n",
    "    axmatrix = fig.add_axes([0.3,0.1,0.6,0.8])\n",
    "    index = Z['leaves']\n",
    "    Dsq = Matrix\n",
    "    Dsq = Dsq[index,:]\n",
    "    Dsq = Dsq[:,index]\n",
    "    im = axmatrix.matshow(Dsq, aspect='auto', origin='lower')\n",
    "    axmatrix.set_xticks([])\n",
    "    axmatrix.set_yticks([])\n",
    "\n",
    "\n",
    "    # Plot colorbar\n",
    "    plt.title(title, fontsize= 20)\n",
    "    axcolor = fig.add_axes([0.91,0.1,0.02,0.8])\n",
    "    pylab.colorbar(im, cax=axcolor)\n",
    "    \n",
    "    plt.savefig('output_plots/' + title + '.png')\n",
    "\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Binning based on dict.\n",
    "Return binned nodes.\n",
    "'''\n",
    "def bin_nodes(data_dict): \n",
    "    bins = set(data_dict.values())\n",
    "\n",
    "    d_binned = {}\n",
    "    for n in bins:\n",
    "        d_binned[n] = [k for k in data_dict.keys() if data_dict[k] == n]\n",
    "        \n",
    "    return d_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Node Properties (color, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generate color list based on color count (i.e. nodes to be coloured).\n",
    "Return list of colors.\n",
    "'''\n",
    "def coloring_nodes(n):\n",
    "    colors = [colorsys.hsv_to_rgb(1.0/n*x,1,1) for x in range(n)]\n",
    "    color_list = []\n",
    "    for c in colors:\n",
    "        cc = [int(y*255) for y in c]\n",
    "        color_list.append('#%02x%02x%02x' % (cc[0],cc[1],cc[2]))\n",
    "        \n",
    "    return color_list\n",
    "\n",
    "\n",
    "'''\n",
    "From generated colors, get lighter or darker subcategorical colors.\n",
    "Return colors in light/dark version.\n",
    "'''\n",
    "def hex_to_rgb(hex):\n",
    "     hex = hex.lstrip('#')\n",
    "     hlen = len(hex)\n",
    "     return tuple(int(hex[i:i+hlen//3], 16) for i in range(0, hlen, hlen//3))\n",
    "\n",
    "def adjust_color_lightness(r, g, b, factor):\n",
    "    h, l, s = rgb2hls(r / 255.0, g / 255.0, b / 255.0)\n",
    "    l = max(min(l * factor, 1.0), 0.0)\n",
    "    r, g, b = hls2rgb(h, l, s)\n",
    "    return rgb2hex(int(r * 255), int(g * 255), int(b * 255))\n",
    "\n",
    "def darken_color(r, g, b, factor=0.9):\n",
    "    return adjust_color_lightness(r, g, b, 1 - factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dimensionality reduction from Matrix (t-SNE).\n",
    "Return dict (keys: node IDs, values: x,y).\n",
    "'''\n",
    "def embed_tsne_2D(DM, prplxty, density, l_rate, steps, metric = 'precomputed'):\n",
    "    \n",
    "    tsne = TSNE(n_components = 2, random_state = 0, perplexity = prplxty, metric = metric,# init='pca',\n",
    "                     early_exaggeration = density,  learning_rate = l_rate ,n_iter = steps)\n",
    "    embed = tsne.fit_transform(DM)\n",
    "    return embed\n",
    "\n",
    "\n",
    "\n",
    "def get_posG(G,embed):\n",
    "    posG = {}\n",
    "    cc = 0\n",
    "    for entz in G.nodes():\n",
    "    #for entz in sorted(G.nodes()):\n",
    "        posG[entz] = (embed[cc,0],embed[cc,1])\n",
    "        cc += 1\n",
    "\n",
    "    return posG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create Node Labels, based on a dict of coordinates (keys:node ID, values: x,y)\n",
    "Return new dict of node iDs and features for each node.\n",
    "'''\n",
    "def labels2D(posG, feature_dict):\n",
    "    labels = {} \n",
    "    c = 0\n",
    "    for node, xy in sorted(posG.items(), key = lambda x: x[1][0]):\n",
    "        labels[node] = ([node,feature_dict[node][0],feature_dict[node][1],feature_dict[node][2],feature_dict[node][3]])   \n",
    "        c+=1\n",
    "        \n",
    "    return labels\n",
    "\n",
    "\n",
    "'''\n",
    "Create label position of coordinates dict.\n",
    "Return new dict with label positions. \n",
    "'''\n",
    "def position_labels(posG, move_x, move_y):\n",
    "    posG_labels = {}\n",
    "    for key,val in posG.items():\n",
    "        xx = val[0] + move_x\n",
    "        yy = val[1] + move_y\n",
    "        posG_labels[key] = (xx,yy)\n",
    "        \n",
    "    return posG_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate the node degree from graph positions (dict).\n",
    "Return list of radii for each node (2D). \n",
    "'''\n",
    "def draw_node_degree(G, scalef):\n",
    "    #x = 20\n",
    "    #ring_frac = np.sqrt((x-1.)/x)\n",
    "    #ring_frac = (x-1.)/x\n",
    "\n",
    "    l_size = []\n",
    "    for node in G.nodes():\n",
    "        k = nx.degree(G, node)\n",
    "        R = scalef * (1 + k**1.1)\n",
    "        #r = ring_frac * R\n",
    "      \n",
    "        l_size.append(R)\n",
    "    \n",
    "    #l_k = [k/max(l_size) for k in l_size]\n",
    "    \n",
    "        \n",
    "    return l_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Validation of Layouts 2D.\n",
    "'''\n",
    "def calc_dist_from_layout(posG):\n",
    "    \n",
    "    l_x= []\n",
    "    l_y=[]\n",
    "    for coords in posG.values():\n",
    "            l_x.append(coords[0])\n",
    "            l_y.append(coords[1])\n",
    "            \n",
    "    p_dist = []\n",
    "    for idx,val in enumerate(l_x):\n",
    "        d_list = []\n",
    "        for c in range(len(l_x)):\n",
    "            for yy in l_y:\n",
    "                d = np.sqrt((l_x[idx]-l_x[c])**2+(l_y[idx]-l_y[c])**2)\n",
    "            d_list.append(d)\n",
    "        p_dist.append(d_list)\n",
    "        \n",
    "    return p_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Generate trace 2D.\n",
    "Return trace. \n",
    "'''\n",
    "def get_trace(x,y,trace_name,colour):\n",
    "    trace = pgo.Scatter(name = trace_name,\n",
    "    x = x,\n",
    "    y = y,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=6,\n",
    "        color=colour\n",
    "    ),)\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANDSCAPE \n",
    "\n",
    "'''\n",
    "From 2D embedded coordinates generate a 3D landscape by including the z-axis.\n",
    "Return x,y,z coordinates, where z is set 0.\n",
    "'''\n",
    "def get_coords_landscape(posG):\n",
    "    # IMPORTANT : sort pos by G.nodes()\n",
    "    posG_sorted = dict([(key, posG[key]) for key in G.nodes()])\n",
    "\n",
    "    df=pd.DataFrame(posG_sorted).T\n",
    "    df['Z'] = 0*len(G.nodes())\n",
    "    df.columns=['X','Y','Z']\n",
    "\n",
    "    x=np.array(df['X'])\n",
    "    y=np.array(df['Y'])\n",
    "    z=np.array(df['Z'])\n",
    "\n",
    "    return x,y,z\n",
    "\n",
    "\n",
    "'''\n",
    "Create trace of vertical connecting edges in between node z0 and node z=parameter (e.g.disease count).\n",
    "Return trace with edges.\n",
    "'''\n",
    "\n",
    "def get_trace_edges_Z(x,y,z0,z):\n",
    "    Xe = []\n",
    "    for u in x:\n",
    "        Xe += [u,u,None]\n",
    "\n",
    "    Ye = []   \n",
    "    for v in y:\n",
    "        Ye += [v,v,None]  \n",
    "\n",
    "    Ze = []  \n",
    "    for w in z0:\n",
    "        for t in z:\n",
    "            Ze += [w,t,None]\n",
    "            \n",
    "    trace_edge = pgo.Scatter3d(\n",
    "        x = Xe, \n",
    "        y = Ye, \n",
    "        z = Ze,\n",
    "        mode = 'lines', hoverinfo='none',\n",
    "        line = dict(width = 3.0, color = 'darkgrey'),\n",
    "        opacity = 0.5\n",
    "    )\n",
    "\n",
    "    return trace_edge\n",
    "\n",
    "'''\n",
    "Create trace of nodes for x,y,z0 and x,y,z=parameter (e.g.disease count).\n",
    "Return traces of nodes.\n",
    "'''\n",
    "\n",
    "def get_trace_nodes_Z(x,y,z0,z):\n",
    "    \n",
    "    trace_z0=pgo.Scatter3d(x=x,y=y,z=z0,\n",
    "                             mode = 'markers',\n",
    "                           text = list(feature_dict_sorted.items()),\n",
    "                           hoverinfo = 'text',\n",
    "                           textposition='middle center',\n",
    "                           marker = dict(\n",
    "                color = colours,\n",
    "                size = size3d,\n",
    "                symbol = 'circle',\n",
    "            ),)\n",
    "\n",
    "    trace_z=pgo.Scatter3d(x=x,y=y,z=z,\n",
    "                             mode = 'markers',\n",
    "                           #text = list(d_gene_dc_sorted.items()),\n",
    "                           hoverinfo = 'text',\n",
    "                           textposition='middle center',\n",
    "                           marker = dict(\n",
    "                color = colours,\n",
    "                size = size3d,\n",
    "                symbol = 'circle',\n",
    "            ),)\n",
    "    \n",
    "    return trace_z0, trace_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate the node degree from graph positions (dict).\n",
    "Return list of radii for each node (3D). \n",
    "'''\n",
    "def draw_node_degree_3D(G, scalef):\n",
    "    x = 20\n",
    "    ring_frac = (x-1.)/x\n",
    "\n",
    "    l_size = []\n",
    "    for node in G.nodes():\n",
    "        k = nx.degree(G, node)\n",
    "        R = scalef * (1+k**1.5)\n",
    "        r = ring_frac * R\n",
    "        l_size.append(r)\n",
    "        \n",
    "        l_size_n = []\n",
    "        for i in l_size:\n",
    "            j = np.sqrt(np.sqrt(i/max(l_size)))\n",
    "            l_size_n.append(j*scalef)\n",
    "        \n",
    "    return l_size_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dimensionality reduction from Matrix (t-SNE).\n",
    "Return dict (keys: node IDs, values: x,y,z).\n",
    "'''\n",
    "def embed_tsne_3D(G, Matrix, prplxty, density, l_rate, n_iter):\n",
    "    #prplxty = 10 # default = 30.\n",
    "    #density = 20. # default 12.\n",
    "    #l_rate = 100. # default 200.\n",
    "    tsne3d = TSNE(n_components = 3, random_state = 0, perplexity = prplxty,\n",
    "                     early_exaggeration = density,  learning_rate = l_rate, n_iter = n_iter)\n",
    "    embed = tsne3d.fit_transform(Matrix)\n",
    "\n",
    "    posG = {}\n",
    "    cc = 0\n",
    "    for entz in sorted(G.nodes()):\n",
    "        posG[entz] = (embed[cc,0],embed[cc,1],embed[cc,2])\n",
    "        cc += 1\n",
    "        \n",
    "    return posG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dimensionality reduction from Matrix (DOSNES - 3D sphere t-SNE).\n",
    "Return dict (keys: node IDs, values: x,y,z).\n",
    "'''\n",
    "def embed_tsne_sphere(G, Matrix, metric = 'precomputed'):\n",
    "    model = dosnes.DOSNES(metric = metric, random_state = 42, max_iter = 10, verbose = 1, learning_rate=1000)\n",
    "    X_tsne_sphere = model.fit_transform(Matrix)\n",
    "\n",
    "    posG = {}\n",
    "    cc = 0\n",
    "    for entz in sorted(G.nodes()):\n",
    "        posG[entz] = (X_tsne_sphere[cc,0],X_tsne_sphere[cc,1], X_tsne_sphere[cc,2])\n",
    "        cc += 1\n",
    "    \n",
    "    return posG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generates 3D coordinates from coloured communities (dict).\n",
    "Return trace.\n",
    "'''\n",
    "def get_trace_nodes(G, posG, infolist, color_list, size):\n",
    "\n",
    "    key_list=list(G.nodes())\n",
    "    trace = pgo.Scatter3d(x=[posG[key_list[i]][0] for i in range(len(key_list))],\n",
    "                           y=[posG[key_list[i]][1] for i in range(len(key_list))],\n",
    "                           z=[posG[key_list[i]][2] for i in range(len(key_list))],\n",
    "                           mode = 'markers',\n",
    "                           text = infolist,\n",
    "                           hoverinfo = 'text',\n",
    "                           #textposition='middle center',\n",
    "                           marker = dict(\n",
    "                color = color_list,\n",
    "                size = size,\n",
    "                symbol = 'circle',\n",
    "            ),\n",
    "        )\n",
    "    \n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot node features within 3D plot. \n",
    "Return trace.\n",
    "'''\n",
    "def get_node_features(posG, features):\n",
    "    \n",
    "    key_list=list(posG.keys())\n",
    "    node_labels = pgo.Scatter3d(x=[posG[key_list[i]][0] for i in range(len(key_list))],\n",
    "                               y=[posG[key_list[i]][1] for i in range(len(key_list))],\n",
    "                               z=[posG[key_list[i]][2] for i in range(len(key_list))],\n",
    "                                text = features,\n",
    "                                mode='text', \n",
    "                                textfont=dict(\n",
    "                                    size=10,\n",
    "                                    color='silver'\n",
    "                                ),\n",
    "                                textposition='top center',\n",
    "                                hoverinfo='none'\n",
    "                               )\n",
    "    return node_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generates edges from 3D coordinates.\n",
    "Returns a trace of edges.\n",
    "'''\n",
    "def get_trace_edges(G, posG, color):\n",
    "    Xe = []\n",
    "    Ye = []\n",
    "    Ze = []\n",
    "    for e in G.edges():\n",
    "        Xe += [posG[e[0]][0],posG[e[1]][0]]\n",
    "        Ye += [posG[e[0]][1],posG[e[1]][1]]\n",
    "        Ze += [posG[e[0]][2],posG[e[1]][2]]\n",
    "\n",
    "    trace_edge = pgo.Scatter3d(\n",
    "        x = Xe, \n",
    "        y = Ye, \n",
    "        z = Ze,\n",
    "        mode = 'lines', hoverinfo='none',\n",
    "        line = dict(width = 0.5, color = color),\n",
    "        opacity = 0.3\n",
    "    )\n",
    "\n",
    "    return trace_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 3D: Sphere in background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generate a trace for 3D plotting a sphere (in the background) with chosen radius.\n",
    "Return trace of sphere.\n",
    "'''\n",
    "def get_trace_sphere(r):\n",
    "    n = 100j # resolution of sphere contours\n",
    "    u, v = np.mgrid[0:pi:n, 0:2 * pi:n]\n",
    "\n",
    "    x=r*np.cos(u)*np.sin(v) \n",
    "    y=r*np.sin(u)*np.sin(v) \n",
    "    z=r*np.cos(v) \n",
    "\n",
    "    sphere_trace = pgo.Surface(\n",
    "                    x = x, \n",
    "                    y = y, \n",
    "                    z = z,\n",
    "                    hoverinfo='skip',\n",
    "                    contours = {'x': {'show':True, 'start':0, 'end':0, 'size':1, 'color' : 'lightgray'},\n",
    "                                'y': {'show':True, 'start':0, 'end':0, 'size':1, 'color' : 'lightgray'},\n",
    "                                'z': {'show':True, 'start':0, 'end':0, 'size':1, 'color' : 'lightgray'}\n",
    "                               }\n",
    "                    , showscale = False\n",
    "                    , opacity = 0)\n",
    "    return sphere_trace "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 3D: frame rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to make 3D html plot rotating.\n",
    "Returns frames, to be used in \"pgo.Figure(frames = frames)\"\n",
    "'''\n",
    "def rotate_z(x, y, z, theta):\n",
    "    w = x+1j*y\n",
    "    return np.real(np.exp(1j*theta)*w), np.imag(np.exp(1j*theta)*w), z "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPORT FUNCTIONS\n",
    "+ Coordinates export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_xyz_to_csv(posG, title):\n",
    "    coords = pd.DataFrame(posG, index = ['X','Y','Z'], columns = nodes).T\n",
    "    coords['Gene ID'] = genes_subset\n",
    "    coords['Cluster ID'] = cluster_community\n",
    "    \n",
    "    return coords.to_csv(title +'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------\n",
    "\n",
    "# SUBDATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST GRAPHS | Bench marking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZACHARYS KARATE NETWORK\n",
    "#G_karate = nx.karate_club_graph()\n",
    "\n",
    "# TREE GRAPH\n",
    "#n = 200 # number of nodes\n",
    "#r = n//(n//4) # branching factor\n",
    "#G = nx.full_rary_tree(r, n)\n",
    "\n",
    "# STAR GRAPH\n",
    "#n = 200\n",
    "#G = nx.star_graph(n)\n",
    "\n",
    "# CYCLE GRAPH\n",
    "#n = 200\n",
    "#G = nx.cycle_graph(n)\n",
    "\n",
    "# DRAW TEST GRAPH \n",
    "#nx.draw(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPI - DISEASE SUBGRAPH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ppi = nx.read_edgelist('input/ppi_elist.txt',data=False)\n",
    "# d_ent_sym, d_sym_ent = genent2sym()\n",
    "\n",
    "d_gene_do = pickle.load( open( \"input/d_gene_do.pkl\", \"rb\" ) )\n",
    "d_do_genes = pickle.load( open( \"input/d_do_genes.pkl\", \"rb\" ) )\n",
    "d_do_names = pickle.load( open( \"input/DO_names.pkl\", \"rb\" ) )\n",
    "d_names_do = {y:x for x,y in d_do_names.items()}\n",
    "\n",
    "\n",
    "# CHOOSE DISEASE CATEGORY \n",
    "disease_category = 'sarcoma'\n",
    "\n",
    "l_disease_genes = []\n",
    "for d_name in d_names_do.keys():\n",
    "    if d_name.find(disease_category) != -1:\n",
    "        #print(d_name,d_names_do[d_name])\n",
    "        try:\n",
    "            l_genes = d_do_genes[d_names_do[d_name]]\n",
    "            for gene in l_genes:\n",
    "                l_disease_genes.append(gene)\n",
    "        except:\n",
    "            #print(d_names_do[d_name],d_name)\n",
    "                pass\n",
    "set_disease_genes = set(l_disease_genes)\n",
    "print('\\nThere are %s genes found to be associated with \"%s\".' %(len(set_disease_genes),disease_category))\n",
    "\n",
    "# SEARCH FOR SPECIFIC SUB-DISEASES WITH GENE ASSOCIATIONS\n",
    "\n",
    "sub_categories = {}\n",
    "for d_name in d_names_do.keys():\n",
    "    if d_name.find(disease_category) != -1:\n",
    "        try:\n",
    "            sub_categories[d_name,d_names_do[d_name]]=len(d_do_genes[d_names_do[d_name]])\n",
    "            #print('specific disease: %s (%s) ; # associated genes: %s' %(d_name,d_names_do[d_name],len(d_do_genes[d_names_do[d_name]])))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "'''\n",
    "# SPECIFY SUB CATEGORY OF DISEASE\n",
    "spec = 'DOID:5093'\n",
    "\n",
    "spec_nodes = []\n",
    "for k,v in d_do_genes.items():\n",
    "    if spec == k:\n",
    "        spec_nodes = v\n",
    "\n",
    "set_spec_nodes = set(spec_nodes)\n",
    "\n",
    "\n",
    "# GRAPH \n",
    "G_sub = G_ppi.subgraph(set_spec_nodes)\n",
    "G_sub_lcc = G_sub.subgraph(max(nx.connected_components(G_sub), key=len)) # largest connected component (lcc)\n",
    "print('The lcc of the %s-sub PPI network contains %s genes.' %(disease_category,G_sub_lcc.number_of_nodes()))\n",
    "\n",
    "G = G_sub_lcc\n",
    "\n",
    "# Check which subcategory was chosen:\n",
    "for k,v in sub_categories.items():\n",
    "    if spec == k[1]:\n",
    "        print(k,v)\n",
    "\n",
    "'''\n",
    "\n",
    "G_sub = G_ppi.subgraph(set_disease_genes)\n",
    "G = G_sub.subgraph(max(nx.connected_components(G_sub), key=len)) # largest connected component (lcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_gene_do # {'389289': ['DOID:11054', .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_do_genes # {'DOID:11054': ['389289',..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_names_do # {'angiosarcoma':'DOID:0001816',...}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPI RANDOM SUBGRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "G_ppi = nx.read_edgelist('input/ppi_elist.txt',data=False)\n",
    "# d_ent_sym, d_sym_ent = genent2sym()\n",
    "\n",
    "# RANDOM SAMPLE \n",
    "\n",
    "N = 1000\n",
    "rand_set = rd.sample(PPI.nodes(), N)\n",
    "\n",
    "PPI_sub = nx.subgraph(PPI, rand_set)\n",
    "G = PPI_sub.subgraph(max(nx.connected_components(PPI_sub), key=len))  # extract lcc graph\n",
    "\n",
    "# test for network to only include lcc \n",
    "#print('Nodes within subgraph:', len(G.nodes()))\n",
    "#nx.draw(G,pos=nx.spring_layout(G)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YEAST PPI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load( open( \"input/BIOGRID-ORGANISM-Saccharomyces_cerevisiae_S288c-3.5.185.mitab.pickle\", \"rb\" ) )\n",
    "\n",
    "Counter(data['Interaction Detection Method'])\n",
    "Counter(data['Interaction Types'])\n",
    "\n",
    "filter_score = data[(data['Interaction Types'] == 'psi-mi:\"MI:0915\"(physical association)') +\n",
    "                    (data['Interaction Types'] == 'psi-mi:\"MI:0407\"(direct interaction)') &\n",
    "                    (data['Taxid Interactor A'] == \"taxid:559292\") & \n",
    "                    (data['Taxid Interactor B'] == \"taxid:559292\") ]\n",
    "\n",
    "g = nx.from_pandas_edgelist(filter_score, '#ID Interactor A', 'ID Interactor B')\n",
    "g.remove_edges_from(nx.selfloop_edges(g)) #remove self loop\n",
    "\n",
    "G_cere = g.subgraph(max(nx.connected_components(g), key=len)) # largest connected component (lcc)\n",
    "G = G_cere\n",
    "\n",
    "# ESSENTIAL GENES \n",
    "cere_gene =pd.read_csv(\"input/Saccharomyces cerevisiae.csv\",\n",
    "           delimiter= ',',\n",
    "           skipinitialspace=True)\n",
    "essential_cere = cere_gene[(cere_gene['essentiality status'] == 'E')]\n",
    "essential_genes_cere_list =  essential_cere['symbols'].tolist()\n",
    "\n",
    "degree= dict(G_cere.degree())\n",
    "\n",
    "mg = mygene.MyGeneInfo()\n",
    "a = mg.querymany(essential_genes_cere_list, scopes='symbol', species=559292)\n",
    "essential_genes_cere_names = pd.DataFrame.from_dict(a)\n",
    "essential_genes_cere_entrez =  essential_genes_cere_names['entrezgene'].tolist()\n",
    "\n",
    "cleaned_entrez_list = [x for x in essential_genes_cere_entrez if str(x) != 'nan']\n",
    "\n",
    "degree_formatted={}\n",
    "for k, v in degree.items():\n",
    "    degree_formatted[k.replace(\"entrez gene/locuslink:\",\"\")] = v\n",
    "    \n",
    "index= []\n",
    "essential = []\n",
    "for i in cleaned_entrez_list:\n",
    "    for (key, val) in degree_formatted.items():\n",
    "        if i==key:\n",
    "            index.append(key)\n",
    "            essential.append(val)  \n",
    "\n",
    "no_essential_cere = cere_gene[(cere_gene['essentiality status'] == 'NE')]\n",
    "no_essential_genes_cere_list =  no_essential_cere['symbols'].tolist()\n",
    "b = mg.querymany(no_essential_genes_cere_list, scopes='symbol', species=559292)\n",
    "no_essential_genes_cere_names = pd.DataFrame.from_dict(b)\n",
    "no_essential_genes_cere_entrez =  no_essential_genes_cere_names['entrezgene'].tolist()\n",
    "cleaned_entrez_list_no = [x for x in no_essential_genes_cere_entrez if str(x) != 'nan']\n",
    "\n",
    "index= []\n",
    "no_essential = []\n",
    "for i in cleaned_entrez_list_no:\n",
    "    for (key, val) in degree_formatted.items():\n",
    "        if i==key:\n",
    "            index.append(key)\n",
    "            no_essential.append(val)\n",
    "            \n",
    "df_cere = pd.DataFrame({'essential': pd.Series(essential), 'no_essential': pd.Series(no_essential)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAPH PROPERTIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degs = dict(G.degree())\n",
    "#nodes = list(G.nodes())\n",
    "#edges = list(G.edges())\n",
    "#n_nodes = len(list(G.nodes()))\n",
    "nx.draw(G,pos=nx.spring_layout(G))\n",
    "        \n",
    "print('Number of nodes i.e. genes: %s' %len(list(G.nodes())))\n",
    "print('Number of edges: %s' %len(list(G.edges())))\n",
    "print('Network density: %.1f%%' %(200.*len(list(G.edges()))/(len(list(G.nodes()))*len(list(G.nodes()))-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_k = list(degs.values())\n",
    "set_k = set(l_k)\n",
    "print('Degree min:', min(l_k))\n",
    "print('Degree max:', max(l_k))\n",
    "\n",
    "d_k_f = {}\n",
    "for k in set_k:\n",
    "    d_k_f[k] = l_k.count(k)\n",
    "#print('Degree counts:',d_k_f)\n",
    "\n",
    "mean_deg = np.mean(l_k)\n",
    "var_deg = np.var(l_k)\n",
    "print('Degree Mean:', mean_deg)\n",
    "print('Degree Variant:', var_deg)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Degree Distribution', fontsize = 20)\n",
    "plt.xlabel('Degree', fontsize = 14)\n",
    "plt.ylabel('P(k)', fontsize = 14)\n",
    "plt.loglog(list(d_k_f.keys()),list(d_k_f.values()),'o',c='#008CA0')\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('PPIdegreedist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE COLLECTION - Topological+Functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### + TOPOLOGICAL FEATURES\n",
    "##### based on: https://networkx.github.io/documentation/stable/reference/algorithms/centrality.html\n",
    "+ degree centrality\n",
    "+ closeness centrality\n",
    "+ betweeness centrality\n",
    "+ eigenvector centrality\n",
    "\n",
    "\n",
    "+ HUBS: \"importance\" score if considered hub and direct hub-adjacent\n",
    "+ PERIPHERAL HUBS (\"Distinctiveness Centrality\") (resource: https://towardsdatascience.com/distinctiveness-centrality-56c1e6762328)\n",
    "___\n",
    "#### + BIOLOGICAL FEATURES (functional parameters) ??? \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORK IN PROGRESS : Add functional parameters to feature collection?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEGREE CENTRALITY\n",
    "+ Node degree: important nodes being involved within high number of interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degs = dict(G.degree())\n",
    "d_deghubs = {}\n",
    "for node, de in sorted(degs.items(),key = lambda x: x[1], reverse = 1):\n",
    "    d_deghubs[node] = round(float(de/max(degs.values())),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLOSENESS CENTRALITY\n",
    "+ Measures how closely a node is connected to all other nodes to highlight f.ex. core-periphery structure, or identify central nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness = nx.closeness_centrality(G)\n",
    "d_clos = {}\n",
    "for node, cl in sorted(closeness.items(), key = lambda x: x[1], reverse = 1):\n",
    "     d_clos[node] = round(cl,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BETWEENESS CENTRALITY \n",
    "+ How many shortest paths between pairs of other nodes in the network go through one node. High BC indicates \"bottleneck nodes\" in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweens = nx.betweenness_centrality(G)\n",
    "d_betw = {}\n",
    "for node, be in sorted(betweens.items(), key = lambda x: x[1], reverse = 1):\n",
    "     d_betw[node] = round(be,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EIGENVECTOR CENTRALITY \n",
    "+ Compute the eigenvector centrality for the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen = nx.eigenvector_centrality(G)\n",
    "d_eigen = {}\n",
    "for node, eig in sorted(eigen.items(), key = lambda x: x[1], reverse = 1):\n",
    "     d_eigen[node] = round(eig,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HUB considered nodes + adjacent nodes\n",
    "+ additional parameter to emphasize importance of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2 # select how many \"important\" nodes based on centrality to choose from\n",
    "\n",
    "d_deghubs_cutoff = {}\n",
    "for node, de in sorted(degs.items(), key = lambda x: x[1], reverse = 1)[:cutoff]:\n",
    "#     print('node %s: degree=%s' %(node,1.*de/max(degs.values())))\n",
    "    d_deghubs_cutoff[node] = de/max(degs.values())\n",
    "    \n",
    "closens = nx.closeness_centrality(G)\n",
    "d_closhubs_cutoff = {}\n",
    "for node, cl in sorted(closens.items(), key = lambda x: x[1], reverse = 1)[:cutoff]:\n",
    "#     print('node %s: closeness=%s' %(node,cl))\n",
    "    d_closhubs_cutoff[node] = cl\n",
    "\n",
    "betweens = nx.betweenness_centrality(G)\n",
    "d_betwhubs_cutoff = {}\n",
    "for node, be in sorted(betweens.items(), key = lambda x: x[1], reverse = 1)[:cutoff]:\n",
    "#     print('node %s: betweeness=%s' %(node,be))\n",
    "    d_betwhubs_cutoff[node] = be\n",
    "    \n",
    "overlap = set(d_deghubs_cutoff.keys()) & set(d_closhubs_cutoff.keys()) & set(d_betwhubs_cutoff.keys())\n",
    "d_node_score = {}\n",
    "for node in overlap:\n",
    "    d_node_score[node] = d_deghubs_cutoff[node]+d_betwhubs_cutoff[node]+d_closhubs_cutoff[node]\n",
    "       \n",
    "print('most important ', len(overlap), ' nodes in network by degree and centrality')    \n",
    "for a,b in sorted(d_node_score.items(), key = lambda x: x[1], reverse = 1):\n",
    "    print(a,b)\n",
    "\n",
    "# Assign \"centrality independent\" score to hubs and their adjacent nodes \n",
    "d_hubs = {}\n",
    "c = 1\n",
    "for nd,score in d_node_score.items():\n",
    "    for node in G.nodes():\n",
    "        if nd == node:\n",
    "            d_hubs[node] = c\n",
    "            c+=1\n",
    "\n",
    "direct_neigh = {}\n",
    "for n in d_hubs.keys():\n",
    "    l = []\n",
    "    for pair in G.edges():\n",
    "        if n == pair[0]:\n",
    "            l.append(pair[1])\n",
    "            direct_neigh[n] = l\n",
    "        elif n == pair[1]:\n",
    "            l.append(pair[0])\n",
    "            direct_neigh[n] = l\n",
    "\n",
    "d_hubsneigh = {}\n",
    "for node,score in d_hubs.items():\n",
    "    for nd,neigh in direct_neigh.items():\n",
    "        for n in neigh:\n",
    "                if node==nd and n not in d_hubs.keys():\n",
    "                    d_hubsneigh[n] = score\n",
    "\n",
    "d_hubs_inclneigh = {**d_hubs,**d_hubsneigh}\n",
    "\n",
    "d_no_hubs = {}\n",
    "for i in G.nodes():\n",
    "    if i not in d_hubs_inclneigh.keys():\n",
    "        d_no_hubs[i] = 0\n",
    "        \n",
    "d_hubscored = {**d_no_hubs,**d_hubs_inclneigh}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PERIPHERAL HUB considered nodes + adjacent nodes\n",
    "+ adding node importance to peripheral hubs, which are the only connection to a certain bunch of peripheral nodes\n",
    "+ maybe referred to as Distinctiveness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distinctiveness.dc import dc_all\n",
    "\n",
    "#Calculate the 5 metrics of Distinctiveness Centrality\n",
    "distinct_central = dc_all(G, normalize = True, alpha = 1)\n",
    "distinct_central = pd.DataFrame(distinct_central).sort_index()\n",
    "\n",
    "d_distinctiveness = dict(distinct_central['D2']) # D2 for not considering arc weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete FEATURE COLLECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same order of node IDs for all features\n",
    "\n",
    "d_deghubs_sorted = {key:d_deghubs[key] for key in sorted(d_deghubs.keys())}\n",
    "d_clos_sorted = {key:d_clos[key] for key in sorted(d_clos.keys())}\n",
    "d_betw_sorted = {key:d_betw[key] for key in sorted(d_betw.keys())}\n",
    "d_eigen_sorted = {key:d_eigen[key] for key in sorted(d_eigen.keys())}\n",
    "d_hubscored_sorted = {key:d_hubscored[key] for key in sorted(d_hubscored.keys())}\n",
    "d_distinct_sorted = {key:d_distinctiveness[key] for key in sorted(d_distinctiveness.keys())}\n",
    "\n",
    "# feature collection\n",
    "feature_dict = dict(zip(d_deghubs_sorted.keys(), zip(\n",
    "                                                     d_deghubs_sorted.values(), \n",
    "                                                     d_clos_sorted.values(), \n",
    "                                                     d_betw_sorted.values(), \n",
    "                                                     d_eigen_sorted.values(),\n",
    "                                                     d_hubscored_sorted.values(),\n",
    "                                                    #d_distinct_sorted.values()\n",
    "                                                    )))\n",
    "\n",
    "# IMPORTANT : sort all feature according to Graph node IDs\n",
    "feature_dict_sorted = {key:feature_dict[key] for key in G.nodes()}\n",
    "feature_df = pd.DataFrame.from_dict(feature_dict_sorted, orient = 'index', columns = ['degs', \n",
    "                                                                                      'clos', \n",
    "                                                                                      'betw', \n",
    "                                                                                      'eigen', \n",
    "                                                                                      'hub score',\n",
    "                                                                                      #'distinctiveness'\n",
    "                                                                                      ]) \n",
    "\n",
    "\n",
    "l_features = [] \n",
    "for i in feature_dict_sorted.items():\n",
    "    k = list(i)\n",
    "    l_features.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df_ascend = feature_df.sort_values(by=['degs'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df_ascend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATRICES\n",
    "+ matrix 1-4 are based on Graph Features, calculating shortest paths / random walks\n",
    "+ matrix 5-8 are based on Feature Collection, calculation pairwise distances, due to similiarities of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict of index:node ID\n",
    "d_idx_entz = {}\n",
    "cc = 0\n",
    "for entz in sorted(G.nodes()):\n",
    "    d_idx_entz[cc] = entz\n",
    "    cc += 1\n",
    "\n",
    "Mspl = np.zeros(len(list(G.nodes())))\n",
    "\n",
    "for n1 in range(len(list(G.nodes()))):\n",
    "    vec = []\n",
    "    for n2 in range(len(list(G.nodes()))):\n",
    "        geneA = d_idx_entz[n1]\n",
    "        geneB = d_idx_entz[n2]\n",
    "        try:\n",
    "            spl = nx.shortest_path_length(G,geneA,geneB)\n",
    "            vec.append(spl)\n",
    "        except nx.NetworkXNoPath:\n",
    "            print('no path')\n",
    "        \n",
    "    Mspl = np.vstack((Mspl,vec))\n",
    "Mspl = np.delete(Mspl, (0), axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart probability\n",
    "r = .8 # originally 0.8\n",
    "\n",
    "alpha = 1.0 # indicating \"randomness\" - originally 1.\n",
    "# Community lastig --> teleportationsmöglichkeit alpha\n",
    "# = Freiheitsgrad \n",
    "\n",
    "# adjacency matrix\n",
    "A = nx.adjacency_matrix(G)\n",
    "DM_adj = A.toarray()\n",
    "\n",
    "# SPL MATRIX\n",
    "DM_spl = Mspl \n",
    "\n",
    "# invert Markov (random walk)\n",
    "DM_m = rnd_walk_matrix2(A, r, alpha, len(G.nodes()))\n",
    "DM_m_mod = np.array([(1-(x/max(x))) for x in DM_m])\n",
    "\n",
    "# -log(Markov) matrix\n",
    "min_log = lambda t: -np.log(t)\n",
    "DM_mlog = np.array([min_log(x/max(x)) for x in DM_m])\n",
    "\n",
    "# scipy \"pdist\" for distance\n",
    "DM_cos = distance.squareform(distance.pdist(feature_df, 'cosine'))\n",
    "DM_eucl = distance.squareform(distance.pdist(feature_df, 'euclidean'))\n",
    "DM_sqeucl = distance.squareform(distance.pdist(feature_df, 'sqeuclidean'))\n",
    "DM_corr = distance.squareform(distance.pdist(feature_df, 'correlation'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NODE COLOURS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLOURING DISTINCTIVENESS CENTRALITY (i.e. topological property)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORK IN PROGRESS : WRITE FUNCTION \n",
    "# colouring a DICT of nodes:scores + colouring the adjacent nodes of such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 5 # select how many \"important\" nodes based on centrality to choose from\n",
    "\n",
    "d_distinctiveness_cutoff = {}\n",
    "for node, d in sorted(distinctiveness.items(), key = lambda x: x[1], reverse = 1)[:cutoff]:\n",
    "    d_distinctiveness_cutoff[node] = d/max(distinctiveness.values())\n",
    "    \n",
    "# CREATE COLORS based on amount required\n",
    "n = len(d_distinctiveness_cutoff)\n",
    "color = coloring_nodes(n)\n",
    "sns.palplot(color)\n",
    "\n",
    "# LIGHTER COLORS for e.g. NEIGHBOURING NODES\n",
    "factor = 1.7 # the higher the lighter\n",
    "color_neigh = []\n",
    "for i in color:\n",
    "    r,g,b = hex_to_rgb(i)\n",
    "    color_light = adjust_color_lightness(r,g,b,factor)\n",
    "    color_neigh.append(color_light)\n",
    "\n",
    "sns.palplot(color_neigh)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# DISTINCTIVENESS: NODES\n",
    "\n",
    "\n",
    "# distinctiveness (peripheral hubs) coloured\n",
    "d_col_distinct = {}\n",
    "for idx,n in enumerate(d_distinctiveness_cutoff.keys()):\n",
    "        d_col_distinct[n] = color[idx]\n",
    "        \n",
    "direct_neigh = {}\n",
    "for n in d_col_distinct.keys():\n",
    "    l = []\n",
    "    for pair in G.edges():\n",
    "        if n == pair[0]:\n",
    "            l.append(pair[1])\n",
    "            direct_neigh[n] = l\n",
    "        elif n == pair[1]:\n",
    "            l.append(pair[0])\n",
    "            direct_neigh[n] = l\n",
    "\n",
    "d_col_neigh = {}\n",
    "for node,col in d_col_distinct.items():\n",
    "    for idx, node in enumerate(d_col_distinct.keys()):\n",
    "        for nd,neigh in direct_neigh.items():\n",
    "            for n in neigh:\n",
    "                if node==nd and n not in d_col_distinct.keys():\n",
    "                    d_col_neigh[n]=color_neigh[idx]\n",
    "\n",
    "d_col = {**d_col_distinct,**d_col_neigh}\n",
    "\n",
    "# nodes with no connection to hub \n",
    "d_grey = {}\n",
    "for i in G.nodes():\n",
    "    if i not in d_col.keys():\n",
    "        d_grey[i] = 'snow'\n",
    "\n",
    "d_col_all = {**d_col_distinct, **d_col_neigh, **d_grey}\n",
    "d_col_all_sorted = {key:d_col_all[key] for key in G.nodes()}\n",
    "\n",
    "l_col_distinct = list(d_col_all_sorted.values())\n",
    "\n",
    "colours = l_col_distinct # NODE COLOURING based on HUBS\n",
    "#sns.palplot(l_col_distinct)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# DISTINCTIVENESS: EDGES \n",
    "\n",
    "# Hub outgoing edges\n",
    "edge_lst = []\n",
    "for edge in G.edges():\n",
    "    for e in edge:\n",
    "        for node in d_col_distinct.keys():\n",
    "            if e == node:\n",
    "                edge_lst.append(edge)\n",
    "                \n",
    "# Color edges based on hubs\n",
    "d_col_edges = {}\n",
    "for e in edge_lst:\n",
    "    for node,col in d_col_distinct.items():\n",
    "        if e[0] == node:\n",
    "            d_col_edges[e]=col\n",
    "        elif e[1] == node:\n",
    "            d_col_edges[e]=col\n",
    "\n",
    "sns.palplot(list(d_col_edges.values()))\n",
    "\n",
    "d_grey_edges = {}\n",
    "for edge in G.edges():\n",
    "    if edge not in d_col_edges.keys(): \n",
    "        d_grey_edges[edge] = 'silver'\n",
    "        \n",
    "d_edges_all = {**d_col_edges, **d_grey_edges}\n",
    "\n",
    "# Sort according to G.edges()\n",
    "d_edges_all_sorted = {key:d_edges_all[key] for key in G.edges()}\n",
    "\n",
    "edge_color = list(d_edges_all_sorted.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLOURING HUBS (i.e. topological property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = len(overlap)\n",
    "color = coloring_nodes(n)\n",
    "sns.palplot(color)\n",
    "\n",
    "# LIGHTER COLORS FOR NEIGHBOURING NODES\n",
    "factor = 1.7 # the higher the lighter\n",
    "color_neigh = []\n",
    "for i in color:\n",
    "    r,g,b = hex_to_rgb(i)\n",
    "    color_light = adjust_color_lightness(r,g,b,factor)\n",
    "    color_neigh.append(color_light)\n",
    "\n",
    "sns.palplot(color_neigh)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# HUBS: NODES \n",
    "\n",
    "# Hubs coloured\n",
    "d_col_hubs = {}\n",
    "for idx,n in enumerate(d_node_score.keys()):\n",
    "        d_col_hubs[n] = color[idx]\n",
    "        \n",
    "direct_neigh = {}\n",
    "for n in d_col_hubs.keys():\n",
    "    l = []\n",
    "    for pair in G.edges():\n",
    "        if n == pair[0]:\n",
    "            l.append(pair[1])\n",
    "            direct_neigh[n] = l\n",
    "        elif n == pair[1]:\n",
    "            l.append(pair[0])\n",
    "            direct_neigh[n] = l\n",
    "\n",
    "d_col_neigh = {}\n",
    "for node,col in d_col_hubs.items():\n",
    "    for idx, node in enumerate(d_col_hubs.keys()):\n",
    "        for nd,neigh in direct_neigh.items():\n",
    "            for n in neigh:\n",
    "                if node==nd and n not in d_col_hubs.keys():\n",
    "                    d_col_neigh[n]=color_neigh[idx]\n",
    "\n",
    "d_col = {**d_col_hubs,**d_col_neigh}\n",
    "\n",
    "# nodes with no connection to hub \n",
    "d_grey = {}\n",
    "for i in G.nodes():\n",
    "    if i not in d_col.keys():\n",
    "        d_grey[i] = 'lightgrey'\n",
    "\n",
    "d_col_all = {**d_col_hubs, **d_col_neigh, **d_grey}\n",
    "d_col_all_sorted = {key:d_col_all[key] for key in G.nodes()}\n",
    "\n",
    "l_col_hubs = list(d_col_all_sorted.values())\n",
    "\n",
    "colours = l_col_hubs # NODE COLOURING based on HUBS\n",
    "#sns.palplot(l_col_hubs)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# HUBS: EDGES \n",
    "\n",
    "# Hub outgoing edges\n",
    "edge_lst = []\n",
    "for edge in G.edges():\n",
    "    for e in edge:\n",
    "        for node in d_col_hubs.keys():\n",
    "            if e == node:\n",
    "                edge_lst.append(edge)\n",
    "                \n",
    "# Color edges based on hubs\n",
    "d_col_edges = {}\n",
    "for e in edge_lst:\n",
    "    for node,col in d_col_hubs.items():\n",
    "        if e[0] == node:\n",
    "            d_col_edges[e]=col\n",
    "        elif e[1] == node:\n",
    "            d_col_edges[e]=col\n",
    "\n",
    "sns.palplot(list(d_col_edges.values()))\n",
    "\n",
    "d_grey_edges = {}\n",
    "for edge in G.edges():\n",
    "    if edge not in d_col_edges.keys(): \n",
    "        d_grey_edges[edge] = 'lightgrey'\n",
    "        \n",
    "d_edges_all = {**d_col_edges, **d_grey_edges}\n",
    "\n",
    "# Sort according to G.edges()\n",
    "d_edges_all_sorted = {key:d_edges_all[key] for key in G.edges()}\n",
    "\n",
    "edge_color = list(d_edges_all_sorted.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLOURING SUBCATEGORIES e.g. Disease subcategory (i.e. functional property)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input = dict\n",
    "\n",
    "n = len(sub_categories)\n",
    "colors = coloring_nodes(n)\n",
    "\n",
    "doid_coloured = {}\n",
    "c=0\n",
    "for k,v in sub_categories.items():\n",
    "    doid_coloured[k[1]]=colors[c]\n",
    "    c+=1\n",
    "    \n",
    "d_gene_colours = {}\n",
    "for doid, gene in d_do_genes.items(): \n",
    "    for i in gene:\n",
    "        for do, col in doid_coloured.items():\n",
    "            if doid == do:\n",
    "                d_gene_colours[i]=col\n",
    "\n",
    "# SORT dict based on G.nodes\n",
    "d_gene_colours_sorted = {key:d_gene_colours[key] for key in G.nodes()}\n",
    "\n",
    "l_col_subcat = list(d_gene_colours_sorted.values())\n",
    "colours = l_col_subcat # NODE COLOURING based on Subcategory\n",
    "edge_color = 'lightgrey'\n",
    "\n",
    "sns.palplot(l_col_subcat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLOURING CLOSENESS CENTRALITY (i.e. topological property)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colour parameter\n",
    "d_to_be_coloured = d_clos # dict sorted by dict.values (that way the biggest value matches darkest colour of palette)\n",
    "\n",
    "\n",
    "# Colouring\n",
    "colour_groups = set(d_to_be_coloured.values())\n",
    "colour_count = len(colour_groups)\n",
    "palette = sns.color_palette('Reds', colour_count)\n",
    "\n",
    "d_colourgroups = {}\n",
    "for n in colour_groups:\n",
    "    d_colourgroups[n] = [k for k in d_to_be_coloured.keys() if d_to_be_coloured[k] == n]\n",
    "    \n",
    "d_colourgroups_sorted = {key:d_colourgroups[key] for key in sorted(d_colourgroups.keys())}\n",
    "\n",
    "d_val_col = {}\n",
    "for idx,val in enumerate(d_colourgroups_sorted):\n",
    "    for ix,v in enumerate(palette):\n",
    "        if idx == ix:\n",
    "            d_val_col[val] = v\n",
    "            \n",
    "d_node_colour = {}\n",
    "for y in d_to_be_coloured.items(): # y[0] = node id, y[1] = val\n",
    "    for x in d_val_col.items(): # x[0] = val, x[1] = (col,col,col)\n",
    "        if x[0] == y[1]:\n",
    "            d_node_colour[y[0]]=x[1]\n",
    "            \n",
    "# SORT dict based on G.nodes\n",
    "d_node_colour_sorted = dict([(key, d_node_colour[key]) for key in G.nodes()])\n",
    "\n",
    "l_col_clos = list(d_node_colour_sorted.values())\n",
    "colours = l_col_clos # NODE COLOURING based on Closeness Centrality\n",
    "edge_color = 'lightgrey'\n",
    "\n",
    "sns.palplot(l_col_clos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------\n",
    "# LAYOUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_factor = 1.0\n",
    "size = draw_node_degree(G, node_factor) # node size based on degree\n",
    "\n",
    "opacity_nodes = 1.0\n",
    "opacity_edges = 0.5\n",
    "fontsize_labels = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Organic spring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forceatlas2 = ForceAtlas2()\n",
    "#posG_spring = forceatlas2.forceatlas2_networkx_layout(G, pos=None, iterations=200)\n",
    "posG_spring = nx.spring_layout(G)\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "plt.title('Organic spring', size=16)\n",
    "plt.xlabel('x - axis', fontsize=16)\n",
    "plt.ylabel('y - axis', fontsize=16)\n",
    "\n",
    "nx.draw_networkx_nodes(G, posG_spring,\n",
    "                       edgecolors = 'k', \n",
    "                       linewidths = 0.5, \n",
    "                       node_color=colours, node_size=size)\n",
    "nx.draw_networkx_edges(G, pos = posG_spring, width = 1., edge_color = edge_color, alpha = opacity_edges)\n",
    "#nx.draw_networkx_labels(G, pos = posG_spring, font_size = fontsize_labels, font_color = 'black')\n",
    "\n",
    "print('Number of Nodes:', len(G.nodes()))\n",
    "#print('Colours: Hubs')\n",
    "#print('Node Size: Disease association count')\n",
    "\n",
    "plt.savefig('output_plots/Organic_spring_layout2D_.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D PORTRAITS | 2D t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING \n",
    "\n",
    "prplxty = 50 # range: 5-50 / default = 30.\n",
    "density = 1.  # default 12.\n",
    "l_rate = 200 # default 200.\n",
    "steps = 250 # min 250\n",
    "\n",
    "\n",
    "# Adjacency Matrix\n",
    "embed_adj = embed_tsne_2D(DM_adj, prplxty, density, l_rate, steps)\n",
    "posG_adj = get_posG(G,embed_adj)\n",
    "\n",
    "# SPL Matrix \n",
    "embed_spl = embed_tsne_2D(DM_spl, prplxty, density, l_rate, steps)\n",
    "posG_spl = get_posG(G,embed_spl)\n",
    "\n",
    "# Markov Matrix\n",
    "embed_m = embed_tsne_2D(DM_m, prplxty, density, l_rate, steps)\n",
    "posG_m = get_posG(G,embed_m)\n",
    "embed_m_mod = embed_tsne_2D(DM_m_mod, prplxty, density, l_rate, steps)\n",
    "posG_m_mod = get_posG(G,embed_m_mod)\n",
    "\n",
    "# Markov -log Matrix \n",
    "embed_mlog = embed_tsne_2D(DM_mlog, prplxty, density, l_rate, steps)\n",
    "posG_mlog =get_posG(G,embed_mlog)\n",
    "\n",
    "\n",
    "# Distance Matrices based on pdist\n",
    "# cosine\n",
    "embed_cos = embed_tsne_2D(DM_cos, prplxty, density, l_rate, steps)\n",
    "posG_cos = get_posG(G,embed_cos)\n",
    "\n",
    "# euclidean\n",
    "embed_eucl = embed_tsne_2D(DM_eucl, prplxty, density, l_rate, steps)\n",
    "posG_eucl = get_posG(G,embed_eucl)\n",
    "\n",
    "# squared euclidean\n",
    "embed_sqeucl = embed_tsne_2D(DM_sqeucl, prplxty, density, l_rate, steps)\n",
    "posG_sqeucl = get_posG(G,embed_sqeucl)\n",
    "\n",
    "# Correlation Pairwise Matrix\n",
    "embed_corr = embed_tsne_2D(DM_corr, prplxty, density, l_rate, steps)\n",
    "posG_corr = get_posG(G,embed_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of nodes:', len(G.nodes()))\n",
    "print('')\n",
    "print('Perplexity:', prplxty)\n",
    "print('Early Exaggeration:', density)\n",
    "print('Learning rate:', l_rate)\n",
    "print('Iterations:', steps)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(25,25))\n",
    "\n",
    "plt.subplot(441)\n",
    "plt.title('Adjacency + t-SNE', size=16)\n",
    "plt.xlabel('tsne comp1')\n",
    "plt.ylabel('tsne comp2')\n",
    "\n",
    "nx.draw_networkx_nodes(G, posG_adj, edgecolors = 'k', linewidths = 0.5, node_color=colours, node_size=size, alpha = opacity_nodes)\n",
    "nx.draw_networkx_edges(G, pos = posG_adj, width = 1., edge_color = edge_color, alpha = opacity_edges)\n",
    "#nx.draw_networkx_nodes(G, posG_adj_mod, node_color=colours, node_size=size, alpha = opacity_nodes)\n",
    "#nx.draw_networkx_edges(G, pos = posG_adj_mod, width = 1., edge_color = 'lightgrey', alpha = opacity_edges)\n",
    "#nx.draw_networkx_labels(G, pos = posG_adj, font_size = fontsize_labels, font_color = 'black')\n",
    "plt.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "\n",
    "\n",
    "plt.subplot(442)\n",
    "plt.title('Shortest Path length + t-SNE', size=16)\n",
    "plt.xlabel('tsne comp1')\n",
    "plt.ylabel('tsne comp2')\n",
    "\n",
    "nx.draw_networkx_nodes(G, posG_spl, edgecolors = 'k', linewidths = 0.5, node_color=colours, node_size=size, alpha = opacity_nodes)\n",
    "nx.draw_networkx_edges(G, pos = posG_spl, width = 1., edge_color = edge_color, alpha = opacity_edges)\n",
    "#nx.draw_networkx_labels(G, pos = posG_spl, font_size = fontsize_labels, font_color = 'black')\n",
    "plt.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "\n",
    "\n",
    "plt.subplot(443)\n",
    "plt.title('Markov + t-SNE', size=16)\n",
    "plt.xlabel('tsne comp1')\n",
    "plt.ylabel('tsne comp2')\n",
    "plt.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "\n",
    "#nx.draw_networkx_nodes(G, posG_m, edgecolors = 'k', linewidths = 0.5, node_color=colours, node_size=size, alpha = opacity_nodes)\n",
    "#nx.draw_networkx_edges(G, pos = posG_m, width = 1., edge_color = 'lightgrey', alpha = opacity_edges)\n",
    "nx.draw_networkx_nodes(G, posG_m_mod, edgecolors = 'k', linewidths = 0.5, node_color=colours, node_size=size, alpha = opacity_nodes)\n",
    "nx.draw_networkx_edges(G, pos = posG_m_mod, width = 1., edge_color = edge_color, alpha = opacity_edges)\n",
    "\n",
    "#nx.draw_networkx_labels(G, pos = posG_m, font_size = fontsize_labels, font_color = 'black')\n",
    "plt.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "\n",
    "plt.subplot(444)\n",
    "plt.title('-log Markov + t-SNE', size=16)\n",
    "plt.xlabel('tsne comp1')\n",
    "plt.ylabel('tsne comp2')\n",
    "\n",
    "nx.draw_networkx_nodes(G, posG_mlog, edgecolors = 'k', linewidths = 0.5, node_color=colours, node_size=size, alpha = opacity_nodes)\n",
    "nx.draw_networkx_edges(G, pos = posG_mlog, width = 1., edge_color = edge_color, alpha = opacity_edges)\n",
    "#nx.draw_networkx_labels(G, pos = posG_mlog, font_size = fontsize_labels, font_color = 'black')\n",
    "plt.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "\n",
    "plt.savefig('output_plots/matrices_4x4_01.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 4 Plots\n",
    "plt.figure(figsize=(25,25))\n",
    "\n",
    "plt.subplot(441)\n",
    "plt.xlabel('tsne comp1')\n",
    "plt.ylabel('tsne comp2')\n",
    "plt.title('PDist Cosine + t-SNE', size=16)\n",
    "\n",
    "nx.draw_networkx_nodes(G, posG_cos, edgecolors = 'k', linewidths = 0.5, node_color=colours, node_size=size, alpha = opacity_nodes)\n",
    "nx.draw_networkx_edges(G, pos = posG_cos, width = 1., edge_color = edge_color, alpha = opacity_edges)\n",
    "#nx.draw_networkx_labels(G, pos = posG_cos, font_size = fontsize_labels, font_color = 'black')\n",
    "plt.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "\n",
    "\n",
    "plt.subplot(442)\n",
    "plt.xlabel('tsne comp1')\n",
    "plt.ylabel('tsne comp2')\n",
    "plt.title('PDist Euclidean + t-SNE', size=16)\n",
    "\n",
    "nx.draw_networkx_nodes(G, posG_eucl, edgecolors = 'k', linewidths = 0.5, node_color=colours, node_size=size, alpha = opacity_nodes)\n",
    "nx.draw_networkx_edges(G, pos = posG_eucl, width = 1., edge_color = edge_color, alpha = opacity_edges)\n",
    "#nx.draw_networkx_labels(G, pos = posG_eucl, font_size = fontsize_labels, font_color = 'black')\n",
    "plt.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "\n",
    "\n",
    "plt.subplot(443)\n",
    "plt.xlabel('tsne comp1')\n",
    "plt.ylabel('tsne comp2')\n",
    "plt.title('PDist Squared euclidean + t-SNE', size=16)\n",
    "\n",
    "nx.draw_networkx_nodes(G, posG_sqeucl, edgecolors = 'k', linewidths = 0.5, node_color=colours, node_size=size, alpha = opacity_nodes)\n",
    "nx.draw_networkx_edges(G, pos = posG_sqeucl, width = 1., edge_color = edge_color, alpha = opacity_edges)\n",
    "#nx.draw_networkx_labels(G, pos = posG_sqeucl, font_size = fontsize_labels, font_color = 'black')\n",
    "plt.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "\n",
    "\n",
    "plt.subplot(444)\n",
    "plt.xlabel('tsne comp1')\n",
    "plt.ylabel('tsne comp2')\n",
    "plt.title('Correlation matrix + t-SNE', size=16)\n",
    "\n",
    "nx.draw_networkx_nodes(G, posG_corr, edgecolors = 'k', linewidths = 0.5, node_color=colours, node_size=size)#, alpha = opacity_nodes)\n",
    "nx.draw_networkx_edges(G, pos = posG_corr, width = 1., edge_color = edge_color, alpha = opacity_edges)\n",
    "#nx.draw_networkx_labels(G, pos = posG_corr, font_size = fontsize_labels, font_color = 'black')\n",
    "plt.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "\n",
    "plt.savefig('output_plots/matrices_4x4_2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,25))\n",
    "\n",
    "plt.title('Adjacency + t-SNE', size=16)\n",
    "plt.xlabel('tsne comp1')\n",
    "plt.ylabel('tsne comp2')\n",
    "\n",
    "nx.draw_networkx_nodes(G, posG_adj, edgecolors = 'k', linewidths = 0.5, node_color=colours, node_size=size, alpha = opacity_nodes)\n",
    "nx.draw_networkx_edges(G, pos = posG_adj, width = 1., edge_color = edge_color, alpha = opacity_edges)\n",
    "#nx.draw_networkx_nodes(G, posG_adj_mod, node_color=colours, node_size=size, alpha = opacity_nodes)\n",
    "#nx.draw_networkx_edges(G, pos = posG_adj_mod, width = 1., edge_color = 'lightgrey', alpha = opacity_edges)\n",
    "#nx.draw_networkx_labels(G, pos = posG_adj, font_size = fontsize_labels, font_color = 'black')\n",
    "plt.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "\n",
    "plt.savefig('output_plots/2D_adj.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,25))\n",
    "plt.xlabel('tsne comp1')\n",
    "plt.ylabel('tsne comp2')\n",
    "plt.title('PDist Squared euclidean + t-SNE', size=16)\n",
    "\n",
    "nx.draw_networkx_nodes(G, posG_sqeucl, edgecolors = 'k', linewidths = 0.5, node_color=colours, node_size=size, alpha = opacity_nodes)\n",
    "nx.draw_networkx_edges(G, pos = posG_sqeucl, width = 1., edge_color = edge_color, alpha = opacity_edges)\n",
    "#nx.draw_networkx_labels(G, pos = posG_sqeucl, font_size = fontsize_labels, font_color = 'black')\n",
    "plt.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "\n",
    "plt.savefig('output_plots/2D_sqeucl.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE LANDSCAPES | 2D t-SNE + Z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_distinct_sort = {key:d_distinctiveness[key] for key in G.nodes()}\n",
    "z_list = list(d_distinct_sort.values())\n",
    "\n",
    "node_factor = 10 # node size factor\n",
    "size3d = draw_node_degree_3D(G, node_factor) # node size based on degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prplxty3d = 50. # range: 5-50 / default = 30.\n",
    "density3d = 1. # default 12.\n",
    "l_rate3d = 1000 # default 200.\n",
    "steps3d = 250 #min 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING \n",
    "\n",
    "adj_x, adj_y, adj_z = get_coords_landscape(posG_adj)\n",
    "adj_trace, adj_trace_z = get_trace_nodes_Z(adj_x, adj_y, adj_z, z_list)\n",
    "adj_edges = get_trace_edges_Z(adj_x, adj_y, adj_z, z_list)\n",
    "data_adj = [adj_trace, adj_trace_z,adj_edges]\n",
    "\n",
    "spl_x, _spl_y, spl_z = get_coords_landscape(posG_spl)\n",
    "spl_trace, spl_trace_z = get_trace_nodes_Z(spl_x, _spl_y, spl_z, z_list)\n",
    "spl_edges = get_trace_edges_Z(spl_x, _spl_y, spl_z, z_list)\n",
    "data_spl = [spl_trace, spl_trace_z, spl_edges]\n",
    "\n",
    "m_x, m_y, m_z = get_coords_landscape(posG_m_mod)\n",
    "m_trace, m_trace_z = get_trace_nodes_Z(m_x, m_y, m_z, z_list)\n",
    "m_edges = get_trace_edges_Z(m_x, m_y, m_z, z_list)\n",
    "data_m = [m_trace, m_trace_z,m_edges]\n",
    "\n",
    "mlog_x, mlog_y, mlog_z = get_coords_landscape(posG_mlog)\n",
    "mlog_trace, mlog_trace_z = get_trace_nodes_Z(mlog_x, mlog_y, mlog_z, z_list)\n",
    "mlog_edges = get_trace_edges_Z(mlog_x, mlog_y, mlog_z, z_list)\n",
    "data_mlog = [mlog_trace, mlog_trace_z,mlog_edges]\n",
    "\n",
    "\n",
    "cos_x, cos_y, cos_z = get_coords_landscape(posG_cos)\n",
    "cos_trace, cos_trace_z = get_trace_nodes_Z(cos_x, cos_y, cos_z, z_list)\n",
    "cos_edges = get_trace_edges_Z(cos_x, cos_y, cos_z, z_list)\n",
    "data_cos = [cos_trace, cos_trace_z,cos_edges]\n",
    "\n",
    "\n",
    "eucl_x, eucl_y, eucl_z = get_coords_landscape(posG_eucl)\n",
    "eucl_trace, eucl_trace_z = get_trace_nodes_Z(eucl_x, eucl_y, eucl_z, z_list)\n",
    "eucl_edges = get_trace_edges_Z(eucl_x, eucl_y, eucl_z, z_list)\n",
    "data_eucl = [eucl_trace, eucl_trace_z,eucl_edges]\n",
    "\n",
    "sqeucl_x, sqeucl_y, sqeucl_z = get_coords_landscape(posG_sqeucl)\n",
    "sqeucl_trace, sqeucl_trace_z = get_trace_nodes_Z(sqeucl_x, sqeucl_y, sqeucl_z, z_list)\n",
    "sqeucl_edges = get_trace_edges_Z(sqeucl_x, sqeucl_y, eucl_z, z_list)\n",
    "data_sqeucl = [sqeucl_trace, sqeucl_trace_z,sqeucl_edges]\n",
    "\n",
    "corr_x, corr_y, corr_z = get_coords_landscape(posG_corr)\n",
    "corr_trace, corr_trace_z = get_trace_nodes_Z(corr_x, corr_y, corr_z, z_list)\n",
    "corr_edges = get_trace_edges_Z(corr_x, corr_y, corr_z, z_list)\n",
    "data_corr = [corr_trace, corr_trace_z,corr_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Perplexity:', prplxty3d)\n",
    "print('Early Exaggeration:', density3d)\n",
    "print('Learning rate:', l_rate3d)\n",
    "print('Iterations:', steps3d)\n",
    "\n",
    "\n",
    "fig_1 = make_subplots(rows = 2, cols = 4,\n",
    "                    specs=2*[4 * [{'type': 'scatter3d'}]],\n",
    "                    print_grid=False, subplot_titles=('Adjacency + t-SNE', \n",
    "                                                     'SPL + t-SNE',\n",
    "                                                     'Markov + t-SNE',\n",
    "                                                     'Markov -log + t-SNE',\n",
    "                                                      'Cosine + t-SNE', \n",
    "                                                     'Euclidean + t-SNE', \n",
    "                                                     'Squared Euclidean + t-SNE',\n",
    "                                                     'Correlation + t-SNE')\n",
    "                    )\n",
    "\n",
    "    \n",
    "for i in data_adj:\n",
    "    fig_1.add_trace(i, row = 1, col = 1)\n",
    "    \n",
    "for i in data_spl:\n",
    "    fig_1.add_trace(i, row = 1, col = 2)\n",
    "    \n",
    "for i in data_m:\n",
    "    fig_1.add_trace(i, row = 1, col = 3)\n",
    "\n",
    "for i in data_mlog:\n",
    "    fig_1.add_trace(i, row = 1, col = 4)\n",
    "\n",
    "\n",
    "for i in data_cos:\n",
    "    fig_1.add_trace(i, row = 2, col = 1)\n",
    "    \n",
    "for i in data_eucl:\n",
    "    fig_1.add_trace(i, row = 2, col = 2)\n",
    "    \n",
    "for i in data_sqeucl:\n",
    "    fig_1.add_trace(i, row = 2, col = 3)\n",
    "\n",
    "for i in data_corr:\n",
    "    fig_1.add_trace(i, row = 2, col = 4)\n",
    "\n",
    "fig_1.update_layout(template='none', showlegend = False, width = 1400, height = 1400)\n",
    "py.iplot(fig_1)\n",
    "\n",
    "plotly.offline.plot(fig_1, filename = 'output_plots/Landscape_2.html', auto_open=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D PORTRAITS | 3D t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WORK IN PROGRESS: FIX EDGE COLOR for 3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this when fixed :\n",
    "edge_color = 'lightgrey'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size3d = 5\n",
    "\n",
    "node_factor = 10 # node size factor\n",
    "size3d = draw_node_degree_3D(G, node_factor) # node size based on degree\n",
    "\n",
    "prplxty3d = 100 # range: 5-50 / default = 30.\n",
    "density3d = 1 # default 12.\n",
    "l_rate3d = 200 # default 200.\n",
    "steps3d = 250 #min 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING \n",
    "\n",
    "# Adjacency Matrix\n",
    "posG3d_adj = embed_tsne_3D(G, DM_adj, prplxty3d, density3d, l_rate3d, steps3d)\n",
    "adj_edges = get_trace_edges(G, posG3d_adj, edge_color) \n",
    "adj_nodes = get_trace_nodes(G, posG3d_adj,  l_features, colours, size3d)\n",
    "data_adj = [adj_edges, adj_nodes]\n",
    "\n",
    "# SPL Matrix \n",
    "posG3d_spl = embed_tsne_3D(G, DM_spl, prplxty3d, density3d, l_rate3d, steps3d)\n",
    "spl_edges = get_trace_edges(G, posG3d_spl, edge_color) \n",
    "spl_nodes = get_trace_nodes(G, posG3d_spl,  l_features, colours, size3d)\n",
    "data_spl = [spl_edges, spl_nodes]\n",
    "\n",
    "# Markov Matrix\n",
    "posG3d_m_mod = embed_tsne_3D(G, DM_m_mod, prplxty3d, density3d, l_rate3d, steps3d)\n",
    "m_edges = get_trace_edges(G, posG3d_m_mod, edge_color) \n",
    "m_nodes = get_trace_nodes(G, posG3d_m_mod, l_features, colours, size3d)\n",
    "data_m = [m_edges, m_nodes]\n",
    "\n",
    "\n",
    "# Markov -log Matrix \n",
    "posG3d_mlog = embed_tsne_3D(G, DM_mlog, prplxty3d, density3d, l_rate3d, steps3d)\n",
    "mlog_edges = get_trace_edges(G, posG3d_mlog, edge_color) \n",
    "mlog_nodes = get_trace_nodes(G, posG3d_mlog, l_features, colours, size3d)\n",
    "data_mlog = [mlog_edges, mlog_nodes]\n",
    "\n",
    "\n",
    "# cosine\n",
    "posG3d_cos = embed_tsne_3D(G, DM_cos, prplxty3d, density3d, l_rate3d, steps3d)\n",
    "cos_edges = get_trace_edges(G, posG3d_cos, edge_color) \n",
    "cos_nodes = get_trace_nodes(G, posG3d_cos, l_features, colours, size3d)\n",
    "data_cos = [cos_edges, cos_nodes]\n",
    "\n",
    "\n",
    "# euclidean\n",
    "posG3d_eucl = embed_tsne_3D(G, DM_eucl, prplxty3d, density3d, l_rate3d, steps3d)\n",
    "eucl_edges = get_trace_edges(G, posG3d_eucl, edge_color) \n",
    "eucl_nodes = get_trace_nodes(G, posG3d_eucl,l_features, colours, size3d)\n",
    "data_eucl = [eucl_edges, eucl_nodes]\n",
    "\n",
    "\n",
    "# seuclidean\n",
    "posG3d_sqeucl = embed_tsne_3D(G, DM_sqeucl, prplxty3d, density3d, l_rate3d, steps3d)\n",
    "sqeucl_edges = get_trace_edges(G, posG3d_sqeucl, edge_color) \n",
    "sqeucl_nodes = get_trace_nodes(G, posG3d_sqeucl, l_features, colours, size3d)\n",
    "data_sqeucl = [sqeucl_edges, sqeucl_nodes]\n",
    "\n",
    "\n",
    "# Correlation Pairwise Matrix\n",
    "posG3d_corr = embed_tsne_3D(G, DM_corr, prplxty3d, density3d, l_rate3d, steps3d)\n",
    "corr_edges = get_trace_edges(G, posG3d_corr, edge_color) \n",
    "corr_nodes = get_trace_nodes(G, posG3d_corr, l_features, colours, size3d)\n",
    "data_corr = [corr_edges, corr_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Perplexity:', prplxty3d)\n",
    "print('Early Exaggeration:', density3d)\n",
    "print('Learning rate:', l_rate3d)\n",
    "print('Iterations:', steps3d)\n",
    "\n",
    "\n",
    "fig1 = make_subplots(rows = 1, cols = 4,\n",
    "                    specs=[4 * [{'type': 'scatter3d'}]],\n",
    "                    print_grid=False, subplot_titles=('Adjacency + t-SNE', \n",
    "                                                     'SPL + t-SNE',\n",
    "                                                     'Markov + t-SNE',\n",
    "                                                     'Markov -log + t-SNE')\n",
    "                    )\n",
    "\n",
    "    \n",
    "for i in data_adj:\n",
    "    fig1.add_trace(i, row = 1, col = 1)\n",
    "    \n",
    "for i in data_spl:\n",
    "    fig1.add_trace(i, row = 1, col = 2)\n",
    "    \n",
    "for i in data_m:\n",
    "    fig1.add_trace(i, row = 1, col = 3)\n",
    "\n",
    "for i in data_mlog:\n",
    "    fig1.add_trace(i, row = 1, col = 4)\n",
    "\n",
    "fig1.update_layout(template='none', showlegend = False, width = 1200, height = 600)\n",
    "py.iplot(fig1)\n",
    "\n",
    "plotly.offline.plot(fig1, filename = 'output_plots/3Dmatrices_1.html', auto_open=False)\n",
    "\n",
    "\n",
    "print('Perplexity:', prplxty3d)\n",
    "print('Early Exaggeration:', density3d)\n",
    "print('Learning rate:', l_rate3d)\n",
    "print('Iterations:', steps3d)\n",
    "\n",
    "\n",
    "fig2 = make_subplots(rows = 1, cols = 4,\n",
    "                    specs=[4 * [{'type': 'scatter3d'}]],\n",
    "                    print_grid=False, subplot_titles=('Cosine + t-SNE', \n",
    "                                                     'Euclidean + t-SNE', \n",
    "                                                     'Squared Euclidean + t-SNE',\n",
    "                                                     'Correlation + t-SNE')\n",
    "                    )\n",
    "\n",
    "for i in data_cos:\n",
    "    fig2.add_trace(i, row = 1, col = 1)\n",
    "    \n",
    "for i in data_eucl:\n",
    "    fig2.add_trace(i, row = 1, col = 2)\n",
    "    \n",
    "for i in data_sqeucl:\n",
    "    fig2.add_trace(i, row = 1, col = 3)\n",
    "\n",
    "for i in data_corr:\n",
    "    fig2.add_trace(i, row = 1, col = 4)\n",
    "\n",
    "fig2.update_layout(template='none', showlegend = False, width = 1200, height = 600)\n",
    "py.iplot(fig2)\n",
    "\n",
    "plotly.offline.plot(fig2, filename = 'output_plots/3Dmatrices_2.html', auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE SPHERESCAPES | DOSNES / t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WORK IN PROGRES: DOSNES settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tSNE optimization \n",
    "\n",
    "momentum = 0.1\n",
    "final_momentum = 0.7\n",
    "mom_switch_iter = 250\n",
    "max_iter = 10\n",
    "learning_rate = 200\n",
    "min_gain = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WORK IN PROGRESS: Sphere count to be modular (also : e.g. disease category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sphere Radius and sphere count parameter settings\n",
    "\n",
    "\n",
    "def embed_tsne_sphere_temp(G, Matrix, rand_state = 0, metric = 'precomputed'):\n",
    "    model = dosnes.DOSNES(momentum = momentum, final_momentum = final_momentum, learning_rate = learning_rate, min_gain = min_gain,\n",
    "    max_iter = max_iter, verbose_freq = 10, metric = metric, verbose = 1, random_state=42)\n",
    "    X_tsne_sphere = model.fit_transform(Matrix)\n",
    "    \n",
    "    posG = {}\n",
    "    cc = 0\n",
    "    for entz in sorted(G.nodes()):\n",
    "        posG[entz] = (X_tsne_sphere[cc,0],X_tsne_sphere[cc,1], X_tsne_sphere[cc,2])\n",
    "        cc += 1\n",
    "    \n",
    "    return posG\n",
    "\n",
    "\n",
    "\n",
    "def get_trace_nodes_temp(posG, r, infolist, colours, size):#, infolist, colours, size, r=1): #, infolist, color_list, size):\n",
    "    key_list=list(posG.keys())\n",
    "\n",
    "    trace = pgo.Scatter3d(x=[posG[key_list[i]][0]*r for i in range(len(key_list))],\n",
    "                           y=[posG[key_list[i]][1]*r for i in range(len(key_list))],\n",
    "                           z=[posG[key_list[i]][2]*r for i in range(len(key_list))],\n",
    "                           mode = 'markers',\n",
    "                           text = infolist,\n",
    "                           hoverinfo = 'text',\n",
    "                           textposition='middle center',\n",
    "                           marker = dict(\n",
    "                color = colours,\n",
    "                size = size,\n",
    "                symbol = 'circle',\n",
    "            ),\n",
    "        )\n",
    "    return trace\n",
    "\n",
    "\n",
    "def get_trace_edges_temp(Xe,Ye,Ze):\n",
    "    \n",
    "    traces_edge = pgo.Scatter3d(\n",
    "            x = Xe, \n",
    "            y = Ye, \n",
    "            z = Ze,\n",
    "            mode = 'lines', hoverinfo='none',\n",
    "            line = dict(width = 0.8, color = 'grey'),\n",
    "            opacity = 0.4\n",
    "        )\n",
    "\n",
    "    return traces_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORK IN PROGRESS : all matrices\n",
    "# here: select which matrix \n",
    "\n",
    "matrix = DM_spl\n",
    "embedded = embed_tsne_sphere_temp(G,matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINNING by Disease Count (i.e. DC)\n",
    "\n",
    "disease_count = []\n",
    "for i in gene_disease_matrix:\n",
    "    i = list(i)\n",
    "    dc = i.count(1)\n",
    "    disease_count.append(dc)   \n",
    "\n",
    "\n",
    "# Dict of gene ID: disease count\n",
    "d_gene_dc = {list(G.nodes())[i] : disease_count[i] for i in range(0, len(disease_count))}\n",
    "\n",
    "# Dict of gene ID: disease count sorted by DC\n",
    "d_dc_gene_sorted = dict(OrderedDict(sorted(d_gene_dc.items(), key=lambda i: i[1])))\n",
    "\n",
    "\n",
    "# Dict of grouped disease counts (e.g. steps: 10)\n",
    "d_dc = {}\n",
    "for k, g in it.groupby(d_dc_gene_sorted.values(), key=lambda n: n//10):\n",
    "    d_dc[k] = list(g)\n",
    "print(d_dc)\n",
    "# Dict of gene ID: radius\n",
    "d_gene_dc = {}\n",
    "for n, dc in d_dc_gene_sorted.items():\n",
    "    for r,dcc in d_dc.items():\n",
    "        for i in dcc:\n",
    "            if dc == i:\n",
    "                d_gene_dc[n] = r\n",
    "\n",
    "gene_dc_bins = bin_nodes(d_gene_dc)\n",
    "l_gene_dc_bins = list(gene_dc_bins.values())\n",
    "\n",
    "nodes_ranked = l_gene_dc_bins\n",
    "\n",
    "nodes_coords=[]\n",
    "for n_lst in nodes_ranked: \n",
    "    l = []\n",
    "    for node, coords in embedded.items():\n",
    "        for n in n_lst: \n",
    "            if node==n:\n",
    "                x = (node,coords)\n",
    "                l.append(x)\n",
    "    nodes_coords.append(l)\n",
    "    \n",
    "l_dict_nodes_coords=[]\n",
    "for n in nodes_coords:\n",
    "    n_dict = dict((x,y) for x, y in n)\n",
    "    l_dict_nodes_coords.append(n_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT : disease count sorted by node ID based on G.nodes()\n",
    "d_gene_dc_sorted = {key:d_gene_dc[key] for key in list(G.nodes())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RADIUS of SPHERES - depending on amount of bins\n",
    "\n",
    "l_radius = []\n",
    "for i in range(len(nodes_coords)):\n",
    "    l_radius.append(i+1)\n",
    "\n",
    "#reverse List of Radii (i.e. biggest radius for biggest node bin)\n",
    "#l_radius = l_radius[::-1]\n",
    "print(l_radius)\n",
    "\n",
    "\n",
    "\n",
    "opacity_nodes = 0.9 \n",
    "#node_factor = 0.5 # node size factor\n",
    "#size3d = draw_node_degree(G, node_factor) # node size based on degree\n",
    "size3d = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRACES \n",
    "\n",
    "\n",
    "# TRACE NODES \n",
    "traces_nodes = []\n",
    "c=0\n",
    "for i in l_dict_nodes_coords:\n",
    "    t = get_trace_nodes_temp(i, l_radius[c], l_features, colours, size3d)\n",
    "    traces_nodes.append(t)\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORK IN PROGRESS\n",
    "# FIX Edges \n",
    "'''\n",
    "# TRACES EDGES\n",
    "all_X = []\n",
    "all_Y = []\n",
    "all_Z = []\n",
    "for elem in range(len(l_dict_nodes_coords)):\n",
    "    new_X = []\n",
    "    new_Y = []\n",
    "    new_Z = []\n",
    "    for node in embedded.items():\n",
    "        for i in l_dict_nodes_coords[elem]:\n",
    "            if node[0] == i:\n",
    "                new_x = node[1][0]*l_radius[elem]\n",
    "                new_y = node[1][1]*l_radius[elem]\n",
    "                new_z = node[1][2]*l_radius[elem]\n",
    "                new_X.append(new_x)\n",
    "                new_Y.append(new_y)\n",
    "                new_Z.append(new_z)\n",
    "    all_X.append(new_X)\n",
    "    all_Y.append(new_Y)\n",
    "    all_Z.append(new_Z)\n",
    "    \n",
    "    \n",
    "traces_edges_all = []\n",
    "for u in all_X:\n",
    "    for v in all_Y:\n",
    "        for w in all_Z:\n",
    "            trace = get_trace_edges_temp(u,v,w)\n",
    "            traces_edges_all.append(trace)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT \n",
    "fig_ = pgo.Figure()\n",
    "\n",
    "for i in traces_nodes:\n",
    "    fig_.add_trace(i)\n",
    "\n",
    "#for i in traces_edges_all:\n",
    "#    fig_.add_trace(i)\n",
    "\n",
    "fig_.update_layout(template='none', showlegend = False, width = 1000, height = 1000)\n",
    "print(\"3D Sphere visualization, Matrix: Distance based on SPL metric\")\n",
    "print(\"Number of Nodes: \", len(G.nodes()))\n",
    "print(\"Number of Edges: \", len(G.edges()))\n",
    "\n",
    "plotly.offline.plot(fig_, filename = 'output_plots/3D_sphere_tests.html', auto_open=False)\n",
    "py.iplot(fig_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D | Sphere plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Embedding Sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background sphere\n",
    "sphere_back = get_trace_sphere(r=1)\n",
    "metric = 'precomputed'\n",
    "\n",
    "# matrices embedded\n",
    "# Adjacency\n",
    "posG_sphere_adj = embed_tsne_sphere(G, DM_adj_mod)\n",
    "sphere_edges_adj = get_trace_edges(G, posG_sphere_adj) \n",
    "sphere_nodes_adj = get_trace_nodes(G, posG_sphere_adj, l_features, colours, size3d)\n",
    "data_sphere_adj = [sphere_nodes_adj, sphere_edges_adj, sphere_back]\n",
    "\n",
    "# SPL\n",
    "posG_sphere_spl = embed_tsne_sphere(G, DM_spl)\n",
    "sphere_edges_spl = get_trace_edges(G, posG_sphere_spl) \n",
    "sphere_nodes_spl = get_trace_nodes(G, posG_sphere_spl, l_features, colours, size3d)\n",
    "data_sphere_spl = [sphere_nodes_spl, sphere_edges_spl, sphere_back]\n",
    "\n",
    "# Markov\n",
    "posG_sphere_m = embed_tsne_sphere(G, DM_m_mod)\n",
    "sphere_edges_m = get_trace_edges(G, posG_sphere_m) \n",
    "sphere_nodes_m = get_trace_nodes(G, posG_sphere_m, l_features, colours, size3d)\n",
    "data_sphere_m = [sphere_nodes_m, sphere_edges_m, sphere_back]\n",
    "\n",
    "# Markov -log\n",
    "posG_sphere_mlog = embed_tsne_sphere(G, DM_mlog)\n",
    "sphere_edges_mlog = get_trace_edges(G, posG_sphere_mlog) \n",
    "sphere_nodes_mlog = get_trace_nodes(G, posG_sphere_mlog, l_features, colours, size3d)\n",
    "data_sphere_mlog = [sphere_nodes_mlog, sphere_edges_mlog, sphere_back]\n",
    "\n",
    "# PDist Cosine\n",
    "posG_sphere_cos = embed_tsne_sphere(G, DM_cos)\n",
    "sphere_edges_cos = get_trace_edges(G, posG_sphere_cos) \n",
    "sphere_nodes_cos = get_trace_nodes(G, posG_sphere_cos, l_features, colours, size3d)\n",
    "data_sphere_cos = [sphere_nodes_cos, sphere_edges_cos, sphere_back]\n",
    "\n",
    "# PDist Euclidean\n",
    "posG_sphere_eucl = embed_tsne_sphere(G, DM_eucl)\n",
    "sphere_edges_eucl = get_trace_edges(G, posG_sphere_eucl) \n",
    "sphere_nodes_eucl = get_trace_nodes(G, posG_sphere_eucl, l_features, colours, size3d)\n",
    "data_sphere_eucl = [sphere_nodes_eucl, sphere_edges_eucl, sphere_back]\n",
    "\n",
    "# PDist squared Euclidean\n",
    "posG_sphere_sqeucl = embed_tsne_sphere(G, DM_sqeucl)\n",
    "sphere_edges_sqeucl = get_trace_edges(G, posG_sphere_sqeucl) \n",
    "sphere_nodes_sqeucl = get_trace_nodes(G, posG_sphere_sqeucl, l_features, colours, size3d)\n",
    "data_sphere_sqeucl = [sphere_nodes_sqeucl, sphere_edges_sqeucl, sphere_back]\n",
    "\n",
    "# Correlation \n",
    "posG_sphere_corr = embed_tsne_sphere(G, DM_corr)\n",
    "sphere_edges_corr = get_trace_edges(G, posG_sphere_corr) \n",
    "sphere_nodes_corr = get_trace_nodes(G, posG_sphere_corr, l_features, colours, size3d)\n",
    "data_sphere_corr = [sphere_nodes_corr, sphere_edges_corr, sphere_back]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_sphere1 = make_subplots(rows = 1, cols = 4,\n",
    "                    specs=[4 * [{'type': 'scatter3d'}]],\n",
    "                    print_grid=False, subplot_titles=('Adjacency + t-SNE', \n",
    "                                                     'SPL + t-SNE',\n",
    "                                                     'Markov + t-SNE',\n",
    "                                                     'Markov -log + t-SNE')\n",
    "                    )    \n",
    "for i in data_sphere_adj:\n",
    "    fig_sphere1.add_trace(i, row = 1, col = 1)\n",
    "    \n",
    "for i in data_sphere_spl:\n",
    "    fig_sphere1.add_trace(i, row = 1, col = 2)\n",
    "    \n",
    "for i in data_sphere_m:\n",
    "    fig_sphere1.add_trace(i, row = 1, col = 3)\n",
    "\n",
    "for i in data_sphere_mlog:\n",
    "    fig_sphere1.add_trace(i, row = 1, col = 4)\n",
    "\n",
    "fig_sphere1.update_layout(template='none', showlegend = False, width = 1200, height = 600)\n",
    "py.iplot(fig_sphere1)\n",
    "plotly.offline.plot(fig_sphere1, filename = 'output_plots/Sphere_matrices_1.html', auto_open=False)\n",
    "\n",
    "\n",
    "\n",
    "fig_sphere2 = make_subplots(rows = 1, cols = 4,\n",
    "                    specs=[4 * [{'type': 'scatter3d'}]],\n",
    "                    print_grid=False, subplot_titles=('Cosine + t-SNE', \n",
    "                                                     'Euclidean + t-SNE', \n",
    "                                                     'Squared Euclidean + t-SNE',\n",
    "                                                     'Correlation + t-SNE')\n",
    "                    )\n",
    "for i in data_sphere_cos:\n",
    "    fig_sphere2.add_trace(i, row = 1, col = 1)\n",
    "    \n",
    "for i in data_sphere_eucl:\n",
    "    fig_sphere2.add_trace(i, row = 1, col = 2)\n",
    "    \n",
    "for i in data_sphere_sqeucl:\n",
    "    fig_sphere2.add_trace(i, row = 1, col = 3)\n",
    "\n",
    "for i in data_sphere_corr:\n",
    "    fig_sphere2.add_trace(i, row = 1, col = 4)\n",
    "\n",
    "fig_sphere2.update_layout(template='none', showlegend = False, width = 1200, height = 600)\n",
    "py.iplot(fig_sphere2)\n",
    "plotly.offline.plot(fig_sphere2, filename = 'output_plots/Sphere_matrices_2.html', auto_open=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION OF 2D/3D LAYOUTS compared to Spring\n",
    "### CALCULATE DISTANCES OF NODES IN LAYOUTS\n",
    "+ Plots to test \"Original Distances\" with embeded Distances \n",
    "+ X-axis = distances of layout, Y-axis = actual Distance Matrix Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 2D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance from embeded Spring layout \n",
    "dist_spring = calc_dist_from_layout(posG_spring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distances from embeded coordinates from matrices \n",
    "dist_adj = calc_dist_from_layout(posG_adj)\n",
    "dist_spl = calc_dist_from_layout(posG_spl)\n",
    "dist_m = calc_dist_from_layout(posG_m_mod)\n",
    "dist_mlog = calc_dist_from_layout(posG_mlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_cos = calc_dist_from_layout(posG_cos)\n",
    "dist_eucl = calc_dist_from_layout(posG_eucl)\n",
    "dist_sqeucl = calc_dist_from_layout(posG_sqeucl)\n",
    "dist_corr = calc_dist_from_layout(posG_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADJ \n",
    "spring_adjtrace = [] \n",
    "for i in range(len(dist_spring)):\n",
    "    spring_adjtrace.append(get_trace(dist_spring[i], DM_adj[i], \"Spring\", \"darkgrey\"))\n",
    "\n",
    "adj_trace = []\n",
    "for i in range(len(dist_adj)):\n",
    "    adj_trace.append(get_trace(dist_adj[i], DM_adj[i], \"Aij\", \"coral\"))\n",
    "\n",
    "data_adj = [\n",
    "    spring_adjtrace, \n",
    "    adj_trace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPL\n",
    "spring_spltrace = [] \n",
    "for i in range(len(dist_spring)):\n",
    "    spring_spltrace.append(get_trace(dist_spring[i], DM_spl[i], \"Spring\", \"darkgrey\"))\n",
    "\n",
    "spl_trace = []\n",
    "for i in range(len(dist_spring)):\n",
    "    spl_trace.append(get_trace(dist_spl[i], DM_spl[i], \"SPL\", \"darkorange\"))\n",
    "\n",
    "data_spl = [\n",
    "    spring_spltrace, \n",
    "    spl_trace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MARKOV\n",
    "spring_mtrace = [] \n",
    "for i in range(len(dist_spring)):\n",
    "    spring_mtrace.append(get_trace(dist_spring[i], DM_m_mod[i], \"Spring\", \"darkgrey\"))\n",
    "\n",
    "m_trace = []\n",
    "for i in range(len(dist_spring)):\n",
    "    m_trace.append(get_trace(dist_m[i], DM_m_mod[i], \"Markov\", \"chocolate\"))\n",
    "\n",
    "data_m = [\n",
    "    spring_mtrace, \n",
    "    m_trace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -log MARKOV\n",
    "spring_mlogtrace = [] \n",
    "for i in range(len(dist_spring)):\n",
    "    spring_mlogtrace.append(get_trace(dist_spring[i], DM_mlog[i], \"Spring\", \"darkgrey\"))\n",
    "\n",
    "mlog_trace = []\n",
    "for i in range(len(dist_spring)):\n",
    "    mlog_trace.append(get_trace(dist_mlog[i], DM_mlog[i], \"-log Markov\", \"orangered\"))\n",
    "\n",
    "data_mlog = [\n",
    "    spring_mlogtrace, \n",
    "    mlog_trace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSINE\n",
    "spring_costrace = [] \n",
    "for i in range(len(dist_spring)):\n",
    "    spring_costrace.append(get_trace(dist_spring[i], DM_cos[i], \"Spring\", \"darkgrey\"))\n",
    "\n",
    "cos_trace = []\n",
    "for i in range(len(dist_spring)):\n",
    "    cos_trace.append(get_trace(dist_cos[i], DM_cos[i], \"Cos\", \"royalblue\"))\n",
    "\n",
    "data_cos = [\n",
    "    spring_costrace, \n",
    "    cos_trace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EUCLIDEAN\n",
    "spring_eucltrace = [] \n",
    "for i in range(len(dist_spring)):\n",
    "    spring_eucltrace.append(get_trace(dist_spring[i], DM_eucl[i], \"Spring\", \"darkgrey\"))\n",
    "\n",
    "eucl_trace = []\n",
    "for i in range(len(dist_spring)):\n",
    "    eucl_trace.append(get_trace(dist_eucl[i], DM_eucl[i], \"Eucl\", \"navy\"))\n",
    "\n",
    "data_eucl = [\n",
    "    spring_eucltrace, \n",
    "    eucl_trace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQUARED EUCLIDEAN\n",
    "spring_sqeucltrace = [] \n",
    "for i in range(len(dist_spring)):\n",
    "    spring_sqeucltrace.append(get_trace(dist_spring[i], DM_sqeucl[i], \"Spring\", \"darkgrey\"))\n",
    "\n",
    "sqeucl_trace = []\n",
    "for i in range(len(dist_spring)):\n",
    "    sqeucl_trace.append(get_trace(dist_sqeucl[i], DM_sqeucl[i], \"Sq Eucl\", \"slategrey\"))\n",
    "\n",
    "data_sqeucl = [\n",
    "    spring_sqeucltrace, \n",
    "    sqeucl_trace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELATION\n",
    "spring_corrtrace = [] \n",
    "for i in range(len(dist_spring)):\n",
    "    spring_corrtrace.append(get_trace(dist_spring[i], DM_corr[i], \"Spring\", \"darkgrey\"))\n",
    "\n",
    "corr_trace = []\n",
    "for i in range(len(dist_spring)):\n",
    "    corr_trace.append(get_trace(dist_corr[i], DM_corr[i], \"Corr\", \"cornflowerblue\"))\n",
    "\n",
    "data_corr = [\n",
    "    spring_corrtrace, \n",
    "    corr_trace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 2, cols = 4,\n",
    "                    specs=2*[4 * [{'type': 'Scatter'}]],\n",
    "                    print_grid=False, \n",
    "                    subplot_titles=('Aij', \n",
    "                                    'SPL',\n",
    "                                    'Markov',\n",
    "                                    '-log Markov',\n",
    "                                   'Cosine',\n",
    "                                   'Euclidean',\n",
    "                                   'Squared Euclidean',\n",
    "                                   'Correlation')\n",
    "                   )\n",
    "\n",
    "    \n",
    "for i in data_adj:\n",
    "    for j in i:\n",
    "        fig.add_trace(j, row=1, col=1)\n",
    "    \n",
    "for i in data_spl:\n",
    "    for j in i:\n",
    "        fig.add_trace(j, row=1, col=2)\n",
    "    \n",
    "for i in data_m:\n",
    "    for j in i:\n",
    "        fig.add_trace(j, row=1, col=3)\n",
    "\n",
    "for i in data_mlog:\n",
    "    for j in i:\n",
    "        fig.add_trace(j, row=1, col=4)\n",
    "        \n",
    "    \n",
    "for i in data_cos:\n",
    "    \n",
    "    for j in i:\n",
    "        fig.add_trace(j, row=2, col=1)\n",
    "    \n",
    "for i in data_eucl:\n",
    "    for j in i:\n",
    "        fig.add_trace(j, row=2, col=2)\n",
    "    \n",
    "for i in data_sqeucl:\n",
    "    for j in i:\n",
    "        fig.add_trace(j, row=2, col=3)\n",
    "\n",
    "for i in data_corr:\n",
    "    for j in i:\n",
    "        fig.add_trace(j, row=2, col=4)\n",
    "\n",
    "fig.update_xaxes(title_text = \"Embedded Distances\")\n",
    "fig.update_yaxes(title_text = \"Calculated Distances\")\n",
    "\n",
    "fig.update_layout(\n",
    "    #xaxis_type=\"log\", \n",
    "    #yaxis_type=\"log\",\n",
    "    template='none',showlegend = False,\n",
    "    height=1600,\n",
    "    width=1800\n",
    ")\n",
    "\n",
    "fig.write_image(\"output_plots/Diagram_Comparison_2D_DM_Embedded.png\")\n",
    "\n",
    "print('Number of Nodes:', len(G.nodes()))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D | Spring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posG_3D = nx.spring_layout(G, dim = 3, iterations=200)\n",
    "size3d=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_spring3D = pgo.Figure()\n",
    "\n",
    "spring_nodes = get_trace_nodes(G, posG_3D, l_features, colours, size3d) \n",
    "spring_edges = get_trace_edges(G, posG_3D) \n",
    "\n",
    "data_spring = [spring_nodes, spring_edges]\n",
    "\n",
    "for i in data_spring:\n",
    "    fig_spring3D.add_trace(i)\n",
    "\n",
    "fig_spring3D.update_layout(template='none', showlegend = False, title='Organic Spring', width = 800, height = 800)\n",
    "py.iplot(fig_spring3D)\n",
    "\n",
    "\n",
    "plotly.offline.plot(fig_spring3D, filename = 'output_plots/spring3D.html', auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dist_from_3Dlayout(posG3d):\n",
    "    \n",
    "    l_x = []\n",
    "    l_y = []\n",
    "    l_z = []\n",
    "    for coords in posG.values():\n",
    "            l_x.append(coords[0])\n",
    "            l_y.append(coords[1])\n",
    "            l_z.append(coords[2])\n",
    "            \n",
    "    p_dist = []\n",
    "    for idx,val in enumerate(l_x):\n",
    "        d_list = []\n",
    "        for c in range(len(l_x)):\n",
    "            for yy in l_y:\n",
    "                d = np.sqrt((l_x[idx]-l_x[c])**2+(l_y[idx]-l_y[c])**2)\n",
    "            d_list.append(d)\n",
    "        p_dist.append(d_list)\n",
    "        \n",
    "    return p_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Regression Line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = dist_spl[0]\n",
    "Y = DM_spl[0]\n",
    "df = pd.DataFrame({'X': X, 'Y':Y})\n",
    "\n",
    "reg = LinearRegression().fit(np.vstack(df['X']), Y)\n",
    "df['bestfit'] = reg.predict(np.vstack(df['X']))\n",
    "\n",
    "fig=pgo.Figure()\n",
    "fig.add_trace(pgo.Scatter(name='Embedded Distance vs Matrix Distance', x=df['X'], y=df['Y'].values, \n",
    "                          mode='markers'))\n",
    "fig.add_trace(pgo.Scatter(name='line of best fit', x=X, y=df['bestfit'], \n",
    "                          mode='lines'))\n",
    "fig.update_layout(template='none',\n",
    "                  height = 600,\n",
    "                  width = 800,\n",
    "                  xaxis_title = 'Embedded Distances', yaxis_title = 'Matrix Distances')\n",
    "print('Linear Regression Line for 1. set of Distances of SPL Matrix and SPL Layout Distances')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posG_3D = nx.spring_layout(G, dim = 3, iterations=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Test for correlation between data sets (DMs to Layouts): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation\n",
    "+ Pearson product-moment correlation coefficients\n",
    "+ The relationship between the correlation coefficient matrix, R, and the covariance matrix, C\n",
    "+ Value can range from -1 to 1, the closer to 1 the more positive linear correlation ( the closer to -1 the more negative linear correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson Correlation coefficient comparison of Spring- to Layouts-coordinates\n",
    "\n",
    "print('Number of Nodes: ', len(G.nodes()))\n",
    "print('')\n",
    "\n",
    "# Aij \n",
    "pearson_spring_adj = np.corrcoef(dist_spring,DM_adj)\n",
    "print('Spring: Mean of Pearson Correlation Coefficient: ',round(np.mean(pearson_spring_adj),4))\n",
    "\n",
    "pearson_adj = np.corrcoef(dist_adj,DM_adj)\n",
    "print('Aij: Mean of Pearson Correlation Coefficient: ',round(np.mean(pearson_adj),4))\n",
    "\n",
    "print('')\n",
    "\n",
    "# SPL\n",
    "pearson_spring_spl = np.corrcoef(dist_spring,DM_spl)\n",
    "print('Spring: Mean of Pearson Correlation Coefficient: ',round(np.mean(pearson_spring_spl),4))\n",
    "\n",
    "pearson_spl = np.corrcoef(dist_spl,DM_spl)\n",
    "print('SPL: Mean of Pearson Correlation Coefficient: ',round(np.mean(pearson_spl),4))\n",
    "\n",
    "print('')\n",
    "\n",
    "# Markov\n",
    "pearson_spring_m = np.corrcoef(dist_spring, DM_m_mod)\n",
    "print('Spring: Mean of Pearson Correlation Coefficient: ',round(np.mean(pearson_spring_m),4))\n",
    "\n",
    "pearson_m = np.corrcoef(dist_m,DM_m_mod)\n",
    "print('Markov: Mean of Pearson Correlation Coefficient: ',round(np.mean(pearson_m),4))\n",
    "\n",
    "print('')\n",
    " \n",
    "    \n",
    "# -log Markov\n",
    "pearson_spring_mlog = np.corrcoef(dist_spring,DM_mlog)\n",
    "print('Spring: Mean of Pearson Correlation Coefficient: ',round(np.mean(pearson_spring_mlog),4))\n",
    "\n",
    "pearson_mlog = np.corrcoef(dist_mlog,DM_mlog)\n",
    "print('-log Markov: Mean of Pearson Correlation Coefficient: ',round(np.mean(pearson_mlog),4))\n",
    "\n",
    "print('')\n",
    "\n",
    "\n",
    "# Cos\n",
    "pearson_spring_cos = np.corrcoef(dist_spring,DM_cos)\n",
    "print('Spring: Mean of Pearson Correlation Coefficient: ', round(np.mean(pearson_spring_cos),4))\n",
    "\n",
    "pearson_cos = np.corrcoef(dist_cos,DM_cos)\n",
    "print('Cosine: Mean of Pearson Correlation Coefficient: ',round(np.mean(pearson_cos),4))\n",
    " \n",
    "print('')\n",
    "\n",
    "\n",
    "# Eucl\n",
    "pearson_spring_eucl = np.corrcoef(dist_spring,DM_eucl)\n",
    "print('Spring: Mean of Pearson Correlation Coefficient: ',round(np.mean(pearson_spring_eucl),4))\n",
    "\n",
    "pearson_eucl = np.corrcoef(dist_eucl,DM_eucl)\n",
    "print('Euclidean: Mean of Pearson Correlation Coefficient: ',round(np.mean(pearson_eucl),4))\n",
    "\n",
    "print('')\n",
    "  \n",
    "    \n",
    "# SqEucl\n",
    "pearson_spring_sqeucl = np.corrcoef(dist_spring,DM_sqeucl)\n",
    "print('Spring: Mean of Pearson Correlation Coefficient: ',round(np.mean(pearson_spring_sqeucl),4))\n",
    "\n",
    "pearson_sqeucl = np.corrcoef(dist_sqeucl,DM_sqeucl)\n",
    "print('Squared Euclidean: Mean of Pearson Correlation Coefficient: ',round(np.mean(pearson_sqeucl),4))\n",
    "\n",
    "print('')\n",
    "\n",
    "\n",
    "# Corr\n",
    "pearson_spring_corr = np.corrcoef(dist_spring,DM_corr)\n",
    "print('Spring: Mean of Pearson Correlation Coefficient: ',round(np.mean(pearson_spring_corr),4))\n",
    "\n",
    "pearson_corr = np.corrcoef(dist_corr,DM_corr)\n",
    "print('Correlation: Mean of Pearson Correlation Coefficient: ',round(np.mean(pearson_corr),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spearman Correlation \n",
    "+ to summarize the strength of the linear relationship between two data samples (Rank correlation)\n",
    "+ Compared to Pearson: assumes a non-gaussian distribution and less sensitive to outliers that are in the tail of both samples - because of limiting the outliers to the value of their ranks \n",
    "+ Value can range from -1 to 1, the closer to 1 the more monotonic relationship between X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "print('Number of Nodes: ', len(G.nodes()))\n",
    "print('')\n",
    "\n",
    "# Spearman Correlation coefficient comparison of Spring- to Layouts-coordinates\n",
    "# Aij \n",
    "spearman_spring_adj, _ = spearmanr(DM_adj, dist_spring)\n",
    "print('Spring: Mean of Spearman Correlation Coefficient: ',round(np.mean(spearman_spring_adj),4))\n",
    "\n",
    "spearman_adj, _ = spearmanr(DM_adj, dist_adj)\n",
    "print('Aij: Mean of Spearman Correlation Coefficient: ',round(np.mean(spearman_adj),4))\n",
    "\n",
    "print('')\n",
    "      \n",
    "      \n",
    "# SPL\n",
    "spearman_spring_spl, _ = spearmanr(DM_spl, dist_spring)\n",
    "print('Spring: Mean of Spearman Correlation Coefficient: ',round(np.mean(spearman_spring_spl),4))\n",
    "\n",
    "spearman_spl, _ = spearmanr(DM_spl,dist_spl)\n",
    "print('SPL: Mean of Spearman Correlation Coefficient: ',round(np.mean(spearman_spl),4))\n",
    "\n",
    "print('')\n",
    "\n",
    "      \n",
    "# Markov\n",
    "spearman_spring_m, _ = spearmanr(DM_m_mod, dist_spring)\n",
    "print('Spring: Mean of Spearman Correlation Coefficient: ',round(np.mean(spearman_spring_m),4))\n",
    "\n",
    "spearman_m, _ = spearmanr(DM_m_mod,dist_m)\n",
    "print('Markov: Mean of Spearman Correlation Coefficient: ',round(np.mean(spearman_m),4))\n",
    "\n",
    "print('')\n",
    "\n",
    "       \n",
    "# -log Markov\n",
    "spearman_spring_mlog, _ = spearmanr(DM_mlog, dist_spring)\n",
    "print('Spring: Mean of Spearman Correlation Coefficient: ',round(np.mean(spearman_spring_mlog),4))\n",
    "\n",
    "spearman_mlog, _ = spearmanr(DM_mlog,dist_mlog)\n",
    "print('-log Markov: Mean of Spearman Correlation Coefficient: ',round(np.mean(spearman_mlog),4))\n",
    "\n",
    "print('')\n",
    "\n",
    "       \n",
    "# Cos\n",
    "spearman_spring_cos, _ = spearmanr(DM_cos, dist_spring)\n",
    "print('Spring: Mean of Spearman Correlation Coefficient: ',round(np.mean(spearman_spring_cos),4))\n",
    "\n",
    "spearman_cos, _ = spearmanr(DM_cos,dist_cos)\n",
    "print('Cosine: Mean of Spearman Correlation Coefficient: ',round(np.mean(spearman_cos),4))\n",
    "\n",
    "print('')\n",
    "\n",
    "       \n",
    "# Eucl\n",
    "spearman_spring_eucl, _ = spearmanr(DM_eucl, dist_spring)\n",
    "print('Spring: Mean of Spearman Correlation Coefficient: ',round(np.mean(spearman_spring_eucl),4))\n",
    "\n",
    "spearman_eucl, _ = spearmanr(DM_eucl,dist_eucl)\n",
    "print('Euclidean: Mean of Spearman Correlation Coefficient: ',round(np.mean(spearman_eucl),4))\n",
    "\n",
    "print('')\n",
    "      \n",
    "      \n",
    "# SqEucl\n",
    "spearman_spring_sqeucl, _ = spearmanr(DM_sqeucl, dist_spring)\n",
    "print('Spring: Mean of Spearman Correlation Coefficient: ',round(np.mean(spearman_spring_sqeucl),4))\n",
    "\n",
    "spearman_sqeucl, _ = spearmanr(DM_cos,dist_sqeucl)\n",
    "print('Squared Euclidean: Mean of Spearman Correlation Coefficient: ',round(np.mean(spearman_sqeucl),4))\n",
    "\n",
    "print('')\n",
    "\n",
    "    \n",
    "# Corr\n",
    "spearman_spring_corr, _ = spearmanr(DM_corr, dist_spring)\n",
    "print('Spring: Mean of Spearman Correlation Coefficient: ',round(np.mean(spearman_spring_corr),4))\n",
    "\n",
    "spearman_corr, _ = spearmanr(DM_corr,dist_corr)\n",
    "print('Correlation: Mean of Spearman Correlation Coefficient: ',round(np.mean(spearman_corr),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ------ WORK IN PROGRESS ------ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D | Graph embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node2Vec\n",
    "+ p prioritizes a breadth-first-search (BFS) \n",
    "+ q prioritizes a depth-first-search (DFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ge.classify import read_node_label, Classifier\n",
    "from ge import Node2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "G=nx.read_edgelist('/Users/chuetter/Desktop/Wiki_edgelist.txt',\n",
    "                       create_using = nx.DiGraph(), nodetype = None, data = [( int)])\n",
    "\n",
    "model=Node2Vec(G, walk_length = 10, num_walks = 80,\n",
    "                   p = 0.25, q = 4, workers = 1)\n",
    "model.train(window_size = 5, iter = 3)\n",
    "embeddings_n2v = model.get_embeddings()\n",
    "\n",
    "model_n2v = TSNE(n_components=2)\n",
    "posG_n2v = embeddings_n2v.fit_transform(model_n2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DeepWalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ge import DeepWalk\n",
    "\n",
    "model_deepwalk = DeepWalk(G,walk_length=10,num_walks=80,workers=1)\n",
    "model_deepwalk.train() # train model\n",
    "embed_deepwalk = model_deepwalk.get_embeddings() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Struc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ge import Struc2Vec\n",
    "\n",
    "model_struc = Struc2Vec(G, 10, 80, workers=4, verbose=40, ) \n",
    "model_struc.train(window_size = 5, iter = 3)\n",
    "embed_struc = model_struc.get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEZIER CURVES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = ([0.0,1.0,0.5],[0.5,1.0,0.0],[1.0,1.0,1.0])\n",
    "curve = bezier.Curve(nodes, degree = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cartesian to polar coordinates\n",
    "# r = √ ( x2 + y2 )\n",
    "# theta = tan-1 ( y / x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML to GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#frames=[]\n",
    "#x_eye = -1.25\n",
    "#y_eye = 2\n",
    "#z_eye = 0.5\n",
    "#for t in np.arange(0, 6.26, 0.1):\n",
    "#    xe, ye, ze = rotate_z(x_eye, y_eye, z_eye, -t)\n",
    "#    frames.append(dict(layout=dict(scene=dict(camera=dict(eye=dict(x=xe, y=ye, z=ze))))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DASH APP | WEB APP \n",
    "## SLIDER IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------\n",
    "# SUPPLEMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kMEANS clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(feature_df)\n",
    "k_cluster=kmeans.predict(feature_df)\n",
    "\n",
    "d_clust_kmeans = dict(zip(G.nodes(),k_cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISEASE COUNT\n",
    "\n",
    "# BINNING by Disease Count (i.e. DC)\n",
    "disease_count = []\n",
    "for i in gene_disease_matrix:\n",
    "    i = list(i)\n",
    "    dc = i.count(1)\n",
    "    disease_count.append(dc)   \n",
    "\n",
    "\n",
    "# Dict of gene ID: disease count\n",
    "d_gene_dc = {list(G.nodes())[i] : disease_count[i] for i in range(0, len(disease_count))}\n",
    "\n",
    "# Node Size by Disease count\n",
    "d_gene_dc_norm = {}\n",
    "for i in d_gene_dc.items():\n",
    "    i_norm = i[1]/max(d_gene_dc.values())\n",
    "    round(i_norm,2)\n",
    "    d_gene_dc_norm[i[0]] = i_norm+0.01\n",
    "\n",
    "\n",
    "# List of node sizes in same order as G.nodes\n",
    "node_size = list(d_gene_dc_norm.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
