{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if using the RWR on functionally-based adjacencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it \n",
    "import sklearn\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import plotly\n",
    "import plotly.graph_objs as pgo\n",
    "import plotly.offline as py\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.io as pio\n",
    "\n",
    "import seaborn as sns\n",
    "import umap\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP parametric resources\n",
    "+ https://colab.research.google.com/drive/1lpdCy7HkC5TRI9LfUtIHBBW8oRO86Nvi?usp=sharing\n",
    "+ https://colab.research.google.com/drive/1lpdCy7HkC5TRI9LfUtIHBBW8oRO86Nvi?usp=sharing#scrollTo=BwAID0P-XWJK\n",
    "+ https://umap-learn.readthedocs.io/en/latest/parametric_umap.html#saving-and-loading-your-model\n",
    "+ https://timsainburg.com/parametric-umap.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# FUNCTIONS for this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# the original function by Felix: \n",
    "# -------------------------------------\n",
    "\n",
    "'''\n",
    "Random Walk Operator with restart probability.\n",
    "Return Matrix.\n",
    "''' \n",
    "def rnd_walk_matrix2(A, r, a, num_nodes):\n",
    "\n",
    "    num = 1*num_nodes\n",
    "    n = num_nodes\n",
    "    factor = float((1-a)/n) # = 0 if alpha = 1.0 \n",
    "\n",
    "    E = np.multiply(factor,np.ones([n,n]))              # prepare 2nd scaling term\n",
    "    A_tele = np.multiply(a,A) + E  #     print(A_tele)\n",
    "    M = normalize(A_tele, norm='l1', axis=0)                                 # column wise normalized MArkov matrix\n",
    "\n",
    "    # mixture of Markov chains\n",
    "    del A_tele\n",
    "    del E\n",
    "\n",
    "    U = np.identity(n,dtype=int) \n",
    "    H = (1-r)*M\n",
    "    H1 = np.subtract(U,H)\n",
    "    del U\n",
    "    del M\n",
    "    del H    \n",
    "\n",
    "    W = r*np.linalg.inv(H1)   \n",
    "\n",
    "    return W\n",
    "\n",
    "\n",
    "# -------------------------------------\n",
    "# rwr modified (as used in this script) \n",
    "# -------------------------------------\n",
    "\n",
    "def rwr_matrix(A, r): \n",
    "    n = len(A) # take the whole network into account = all nodes are seed nodes\n",
    "    factor = 1 \n",
    "    a = 1 # maximum freedom to jump anytime to any node within the network\n",
    "    \n",
    "    E = np.multiply(factor,np.ones([n,n])) # Matrix with all 1 --> to \n",
    "    A_tele = np.multiply(a,A) + E  #     print(A_tele)\n",
    "    M = normalize(A_tele, norm='l1', axis=0)                                 # column wise normalized MArkov matrix\n",
    "\n",
    "    # mixture of Markov chains\n",
    "    del A_tele\n",
    "    del E\n",
    "\n",
    "    U = np.identity(n,dtype=int) \n",
    "    H = (1-r)*M\n",
    "    H1 = np.subtract(U,H)\n",
    "    del U\n",
    "    del M\n",
    "    del H    \n",
    "\n",
    "    W = r*np.linalg.inv(H1)   \n",
    "\n",
    "    return W\n",
    "\n",
    "\n",
    "# -------------------------------------\n",
    "# rwr simulated (just for testing, output = path from random walker)\n",
    "# -------------------------------------\n",
    "\n",
    "def random_walk_simple(start_v, number_of_steps):\n",
    "\n",
    "    for step in range(1, number_of_steps):\n",
    "\n",
    "        start_vertex = start_v # index of vertex to start from\n",
    "        visited_vertices = {} # Dictionary that associate nodes with the amount of times it was visited   \n",
    "\n",
    "        path = [start_vertex] # Store and print path  \n",
    "\n",
    "        counter = 0 # Restart the cycle\n",
    "        for counter in range(1, number_of_steps): \n",
    "            vertex_neighbors = [n for n in G.neighbors(start_vertex)] # get adjacent nodes\n",
    "            probability = [] # Set probability of going to a neighbour is uniform\n",
    "            probability = probability + [1./len(vertex_neighbors)] * len(vertex_neighbors)\n",
    "\n",
    "            start_vertex = np.random.choice(vertex_neighbors, p=probability) # Choose a vertex from the vertex neighborhood to start the next random walk\n",
    "\n",
    "            if start_vertex in visited_vertices: # Accumulate the amount of times each vertex is visited\n",
    "                visited_vertices[start_vertex] += 1\n",
    "            else:\n",
    "                visited_vertices[start_vertex] = 1\n",
    "\n",
    "            path.append(start_vertex) # Append to path\n",
    "\n",
    "        # mostvisited = sorted(visited_vertices, key = visited_vertices.get,reverse = True) # Organize the vertex list in most visited decrescent order\n",
    "        # print(\"Path: \", path)\n",
    "        # print(\"Most visited nodes: \", mostvisited[:10]) # Separate the top 10 most visited vertex\n",
    "        \n",
    "        return path\n",
    "\n",
    "    \n",
    "# -------------------------------------\n",
    "# plotting functions \n",
    "# -------------------------------------   \n",
    "\n",
    "def draw_node_degree(G, scalef):\n",
    "    #x = 20\n",
    "    #ring_frac = np.sqrt((x-1.)/x)\n",
    "    #ring_frac = (x-1.)/x\n",
    "\n",
    "    l_size = {}\n",
    "    for node in G.nodes():\n",
    "        k = nx.degree(G, node)\n",
    "        R = scalef * (1 + k**1.1) \n",
    "\n",
    "        l_size[node] = R\n",
    "        \n",
    "    return l_size\n",
    "\n",
    "\n",
    "def draw_node_degree_3D(G, scalef):\n",
    "    x = 3\n",
    "    ring_frac = (x-1.)/x\n",
    "\n",
    "    deg = dict(G.degree())\n",
    "    \n",
    "    d_size = {}\n",
    "    for i in G.nodes():\n",
    "        for k,v in deg.items():\n",
    "            if i == k:\n",
    "                R = scalef * (1+v**0.9)\n",
    "                r = ring_frac * R\n",
    "                d_size[i] = R\n",
    "    \n",
    "    return d_size \n",
    "\n",
    "\n",
    "def embed_umap_2D(Matrix, n_neighbors, spread, min_dist, metric='cosine'):\n",
    "    n_components = 2 # for 2D\n",
    "\n",
    "    U = umap.UMAP(\n",
    "        n_neighbors = n_neighbors,\n",
    "        spread = spread,\n",
    "        min_dist = min_dist,\n",
    "        n_components = n_components,\n",
    "        metric = metric)\n",
    "    embed = U.fit_transform(Matrix)\n",
    "    \n",
    "    return embed\n",
    "\n",
    "\n",
    "def get_posG_2D(l_nodes, embed):\n",
    "    posG = {}\n",
    "    cc = 0\n",
    "    for entz in l_nodes:\n",
    "        # posG[str(entz)] = (embed[cc,0],embed[cc,1])\n",
    "        posG[entz] = (embed[cc,0],embed[cc,1])\n",
    "        cc += 1\n",
    "\n",
    "    return posG\n",
    "\n",
    "\n",
    "def get_posG_3D(l_genes, embed):\n",
    "    posG = {}\n",
    "    cc = 0\n",
    "    for entz in l_genes:\n",
    "        posG[entz] = (embed[cc,0],embed[cc,1],embed[cc,2])\n",
    "        cc += 1\n",
    "    \n",
    "    return posG\n",
    "\n",
    "\n",
    "def color_nodes_from_dict(G, d_to_be_coloured, color_method):\n",
    "\n",
    "    # Colouring\n",
    "    colour_groups = set(d_to_be_coloured.values())\n",
    "    colour_count = len(colour_groups)\n",
    "    pal = sns.color_palette('YlOrRd', colour_count)\n",
    "    palette = pal.as_hex()\n",
    "\n",
    "    d_colourgroups = {}\n",
    "    for n in colour_groups:\n",
    "        d_colourgroups[n] = [k for k in d_to_be_coloured.keys() if d_to_be_coloured[k] == n]\n",
    "        \n",
    "    d_colourgroups_sorted = {key:d_colourgroups[key] for key in sorted(d_colourgroups.keys())}\n",
    "\n",
    "    d_val_col = {}\n",
    "    for idx,val in enumerate(d_colourgroups_sorted):\n",
    "        for ix,v in enumerate(palette):\n",
    "            if idx == ix:\n",
    "                d_val_col[val] = v\n",
    "\n",
    "    d_node_colour = {}\n",
    "    for y in d_to_be_coloured.items(): # y[0] = node id, y[1] = val\n",
    "        for x in d_val_col.items(): # x[0] = val, x[1] = (col,col,col)\n",
    "            if x[0] == y[1]:\n",
    "                d_node_colour[y[0]]=x[1]\n",
    "\n",
    "    # SORT dict based on G.nodes\n",
    "    d_node_colour_sorted = dict([(key, d_node_colour[key]) for key in G.nodes()])\n",
    "    l_col = list(d_node_colour_sorted.values())\n",
    "    colours = l_col\n",
    "\n",
    "    return colours\n",
    "\n",
    "def color_clusters_from_dict(G, d_to_be_coloured, color_method):\n",
    "\n",
    "    # Colouring\n",
    "    colour_groups = set(d_to_be_coloured.values())\n",
    "    colour_count = len(colour_groups)\n",
    "    pal = sns.color_palette('Spectral', colour_count)\n",
    "    palette = pal.as_hex()\n",
    "\n",
    "    d_colourgroups = {}\n",
    "    for n in colour_groups:\n",
    "        d_colourgroups[n] = [k for k in d_to_be_coloured.keys() if d_to_be_coloured[k] == n]\n",
    "        \n",
    "    d_colourgroups_sorted = {key:d_colourgroups[key] for key in sorted(d_colourgroups.keys())}\n",
    "\n",
    "    d_val_col = {}\n",
    "    for idx,val in enumerate(d_colourgroups_sorted):\n",
    "        for ix,v in enumerate(palette):\n",
    "            if idx == ix:\n",
    "                d_val_col[val] = v\n",
    "\n",
    "    d_node_colour = {}\n",
    "    for y in d_to_be_coloured.items(): # y[0] = node id, y[1] = val\n",
    "        for x in d_val_col.items(): # x[0] = val, x[1] = (col,col,col)\n",
    "            if x[0] == y[1]:\n",
    "                d_node_colour[y[0]]=x[1]\n",
    "\n",
    "    # SORT dict based on G.nodes\n",
    "    d_node_colour_sorted = dict([(key, d_node_colour[key]) for key in G.nodes()])\n",
    "    l_col = list(d_node_colour_sorted.values())\n",
    "    colours = l_col\n",
    "    \n",
    "    return colours\n",
    "\n",
    "\n",
    "def embed_umap_3D(Matrix, n_neighbors, spread, min_dist, metric='cosine'):\n",
    "    n_components = 3 # for 3D\n",
    "\n",
    "    U_3d = umap.UMAP(\n",
    "        n_neighbors = n_neighbors,\n",
    "        spread = spread,\n",
    "        min_dist = min_dist,\n",
    "        n_components = n_components,\n",
    "        metric = metric)\n",
    "    embed = U_3d.fit_transform(Matrix)\n",
    "    \n",
    "    return embed\n",
    "\n",
    "\n",
    "def get_posG_3D(l_genes, embed):\n",
    "    posG = {}\n",
    "    cc = 0\n",
    "    for entz in l_genes:\n",
    "        posG[entz] = (embed[cc,0],embed[cc,1],embed[cc,2])\n",
    "        cc += 1\n",
    "    \n",
    "    return posG\n",
    "\n",
    "\n",
    "def get_trace_nodes_3D(posG, info_list, color_list, size):\n",
    "\n",
    "    key_list=list(posG.keys())\n",
    "    trace = pgo.Scatter3d(x=[posG[key_list[i]][0] for i in range(len(key_list))],\n",
    "                           y=[posG[key_list[i]][1] for i in range(len(key_list))],\n",
    "                           z=[posG[key_list[i]][2] for i in range(len(key_list))],\n",
    "                           mode = 'markers',\n",
    "                           text = info_list,\n",
    "                           hoverinfo = 'text',\n",
    "                           #textposition='middle center',\n",
    "                           marker = dict(\n",
    "                color = color_list,\n",
    "                size = size,\n",
    "                symbol = 'circle',\n",
    "                line = dict(width = 1.0,\n",
    "                        color = color_list)\n",
    "            ),\n",
    "        )\n",
    "    \n",
    "    return trace\n",
    "\n",
    "\n",
    "def get_trace_edges_3D(G, posG, color_list, opac = 0.2):\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    edge_z = []\n",
    "    for edge in G.edges():\n",
    "        x0, y0, z0 = posG[edge[0]]\n",
    "        x1, y1, z1 = posG[edge[1]]\n",
    "        edge_x.append(x0)\n",
    "        edge_x.append(x1)\n",
    "        edge_x.append(None)\n",
    "        edge_y.append(y0)\n",
    "        edge_y.append(y1)\n",
    "        edge_y.append(None)\n",
    "        edge_z.append(z0)\n",
    "        edge_z.append(z1)\n",
    "        edge_z.append(None)\n",
    "\n",
    "    trace_edges = pgo.Scatter3d(\n",
    "                        x = edge_x, \n",
    "                        y = edge_y, \n",
    "                        z = edge_z,\n",
    "                        mode = 'lines', hoverinfo='none',\n",
    "                        line = dict(width = 0.5, color = color_list),\n",
    "                        opacity = opac\n",
    "                )\n",
    "    \n",
    "    return trace_edges\n",
    "\n",
    "\n",
    "def color_nodes_same(G, list_color_nodes, color):\n",
    "\n",
    "    d_col = {}\n",
    "    for node in list_color_nodes:\n",
    "            d_col[node] = color\n",
    "      \n",
    "    return d_col "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get human PPI + functional feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = 'Human'\n",
    "\n",
    "G = nx.read_edgelist('input/ppi_elist.txt',data=False)\n",
    "# d_ent_sym, d_sym_ent = genent2sym()\n",
    "\n",
    "d_gene_do = pickle.load( open( \"input/d_gene_do.pkl\", \"rb\" ) )\n",
    "d_do_genes = pickle.load( open( \"input/d_do_genes.pkl\", \"rb\" ) )\n",
    "d_do_names = pickle.load( open( \"input/DO_names.pkl\", \"rb\" ) )\n",
    "d_names_do = {y:x for x,y in d_do_names.items()}\n",
    "\n",
    "df_gene_sym = pd.read_csv('output_csv/DF_gene_symbol_Human.csv', index_col=0)\n",
    "l_features = list((df_gene_sym.to_dict()).values())\n",
    "\n",
    "posG_entrez = []\n",
    "for k in G.nodes():\n",
    "    posG_entrez.append(k)\n",
    "    \n",
    "    \n",
    "features_MF = pd.read_csv('output_csv/Features_GO_MolFunc_Dataframe_Human.csv', index_col=0)\n",
    "feat_genes = list(features_MF.index)\n",
    "\n",
    "features_MF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Feature top list i.e. features with most genes associated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUM UP ROWS to see max-gene-count associated with feature-value\n",
    "feat_array = features_MF.to_numpy()\n",
    "\n",
    "# GET FEATURES TOP LIST\n",
    "feat_col_added = [sum(x) for x in zip(*feat_array)]\n",
    "\n",
    "feat_col_names = list(features_MF.columns)\n",
    "d_feat_col = dict(zip(feat_col_names,feat_col_added))\n",
    "d_feat_col_sorted = {k: v for k, v in sorted(d_feat_col.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "lower_bound = 100 # 0 # 100\n",
    "upper_bound = 200 # 10000 # 200\n",
    "num_of_features = upper_bound-lower_bound\n",
    "\n",
    "\n",
    "d_feat_toplist = {}\n",
    "for k,v in d_feat_col_sorted.items():\n",
    "    if v >= lower_bound and v <= upper_bound: \n",
    "        d_feat_toplist[k] = v\n",
    "\n",
    "print('Number of top features based on selection:',len(d_feat_toplist))\n",
    "#print('Biological Function(s) basis for \"artificial\" Adjacency Matrix:', d_feat_toplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM TOPLIST check for genes associated with features  \n",
    "feat_top_genes = []\n",
    "for feature,genes in features_MF.iteritems():\n",
    "    for top in d_feat_toplist.keys():\n",
    "        if top == feature:\n",
    "            for k,v in genes.items():\n",
    "                if v == 1:\n",
    "                    feat_top_genes.append(int(k))             \n",
    "                    \n",
    "feat_top_genes_sort = sorted(feat_top_genes)\n",
    "print('Number of genes associated with feature function:',len(list(set(feat_top_genes_sort))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct \"Feature-based Adjacency Matrix\" (\"artificial adjacencies\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct empty matrix to be filled with values based on feature-associations\n",
    "\n",
    "# original graph row names\n",
    "graph_row_names = []\n",
    "for i in list(G.nodes()):\n",
    "    graph_row_names.append(int(i))\n",
    "\n",
    "empty_matrix = np.zeros(shape=(len(graph_row_names),len(graph_row_names)))\n",
    "empty_df = pd.DataFrame(empty_matrix, index = graph_row_names, columns = graph_row_names)\n",
    "empty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a matrix with all feature-associated genes (values = 1) \n",
    "\n",
    "# feature genes row names\n",
    "feat_row_names = [str(i) for i in feat_top_genes_sort]\n",
    "\n",
    "feat_graph_overlapping_genes = []\n",
    "for i in graph_row_names:\n",
    "    if str(i) in feat_row_names: \n",
    "        feat_graph_overlapping_genes.append(int(i))\n",
    "            \n",
    "feat_genes_values_matrix = np.ones([len(feat_graph_overlapping_genes),len(feat_graph_overlapping_genes)])\n",
    "df_feat_genes = pd.DataFrame(feat_genes_values_matrix, index = feat_graph_overlapping_genes, columns = feat_graph_overlapping_genes)\n",
    "np.fill_diagonal(df_feat_genes.values, 0)\n",
    "df_feat_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_feat_genes\n",
    "df2 = empty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMNS : merging df1 and df2 by replacing 0 to 1 if gene in feature function list\n",
    "\n",
    "for i,v in df2.iteritems():\n",
    "    for k in df1.index:\n",
    "        if i == k:\n",
    "            df2[i] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if specific column values are overwritten i.e. value = 1 \n",
    "\n",
    "print(df2.loc[66008,4928])\n",
    "print(df2.loc[66008,1994])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROWS : merging df1 and df2 by replacing 0 to 1 if gene in feature function list\n",
    "\n",
    "for i in df2.index:\n",
    "    for k in df1.index:\n",
    "        if i == k:\n",
    "            df2.loc[i,] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if specific row values are overwritten i.e. value = 1 \n",
    "df2.iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if diagonal values are 0\n",
    "print(df2.loc[1994,1994])\n",
    "\n",
    "np.fill_diagonal(df2.values, 0)\n",
    "\n",
    "# check again \n",
    "print(df2.loc[1994,1994])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artificial_adjacency = df2\n",
    "df_artificial_adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artificial_adjacency.loc[66008,4928]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artificial_adjacency.loc[4928,66008]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjacency Matrices - structural + functional for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional features based Aij\n",
    "A_features = df_artificial_adjacency.to_numpy()\n",
    "\n",
    "# Structural features based Aij\n",
    "A_graph = nx.adjacency_matrix(G)\n",
    "A = A_graph.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional feature-based RWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "r = 0.8 # restart probability to \n",
    "func_rwr_matrix = rwr_matrix(A_features,r)\n",
    "\n",
    "\n",
    "df_func = pd.DataFrame(func_rwr_matrix, columns = list(G.nodes()), index=list(G.nodes()))\n",
    "df_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structural/classic RWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_rwr_matrix = rwr_matrix(A,r)\n",
    "\n",
    "df_struct = pd.DataFrame(struct_rwr_matrix, columns = list(G.nodes()), index=list(G.nodes()))\n",
    "df_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT FOR EMBEDDING ≠ Distance Matrix, but instead FEATURE MATRIX\n",
    "\n",
    "#DM = df_struct\n",
    "#feature='structural'\n",
    "\n",
    "DM = df_func\n",
    "feature='functional'\n",
    "\n",
    "# set gene list (= G.nodes())\n",
    "# all having the same order as G.nodes() \n",
    "genes = []\n",
    "for i in DM.index:\n",
    "    genes.append(str(i))\n",
    "\n",
    "genes_rest = [] \n",
    "for g in G.nodes():\n",
    "    if g not in genes:\n",
    "        genes_rest.append(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    " # VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node, Edge colors\n",
    "\n",
    "edge_width = 0.1\n",
    "edge_color = 'lightgrey'\n",
    "\n",
    "edge_colordark = 'dimgrey'\n",
    "opacity_edges = 0.5\n",
    "\n",
    "opacity_nodes = 1.0\n",
    "node_edge_color = None\n",
    "\n",
    "\n",
    "# Node sizes \n",
    "\n",
    "#size = 10.0\n",
    "#size3d = 5.0\n",
    "\n",
    "# if node size reflects degree : \n",
    "\n",
    "scalef= 0.25\n",
    "size = list(draw_node_degree(G, scalef).values())\n",
    "\n",
    "scalef= 0.05\n",
    "size3d = list(draw_node_degree_3D(G, scalef).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-parametric UMAP 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 20 # balance between local and global structure in the data\n",
    "spread = 1.0\n",
    "min_dist = 0.1 # defines how dense points are stacked together \n",
    "metric ='cosine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "umap_2D = embed_umap_2D(DM, n_neighbors, spread, min_dist, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "posG_umap = get_posG_2D(genes, umap_2D)\n",
    "posG_complete_umap = {key:posG_umap[key] for key in G.nodes()}\n",
    "\n",
    "# normalize coordinates (for DataDivr Layout input)\n",
    "x_list = []\n",
    "y_list = []\n",
    "for k,v in posG_complete_umap.items():\n",
    "    x_list.append(v[0])\n",
    "    y_list.append(v[1])\n",
    "    \n",
    "xx_norm = sklearn.preprocessing.minmax_scale(x_list, feature_range=(0, 1), axis=0, copy=True)\n",
    "yy_norm = sklearn.preprocessing.minmax_scale(y_list, feature_range=(0, 1), axis=0, copy=True)\n",
    "\n",
    "posG_complete_umap_norm = dict(zip(list(G.nodes()), zip(xx_norm,yy_norm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Colour Settings to choose: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 1. Spectral Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral Clustering \n",
    "\n",
    "n_clus = 50 #len(d_feat_toplist)\n",
    "color_method = 'spectral'\n",
    "\n",
    "model = SpectralClustering(n_clusters=n_clus,n_components = 2, affinity='nearest_neighbors')\n",
    "clusterid = model.fit_predict(df_posG)\n",
    "\n",
    "d_node_clusterid = dict(zip(list(G.nodes()), clusterid))\n",
    "\n",
    "# uncomment to set colours\n",
    "colours = color_clusters_from_dict(G, d_node_clusterid, color_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 2. Centrality Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centrality metrics \n",
    "color_method = 'clos'\n",
    "\n",
    "df_centralities = pd.read_csv('output_csv/Features_centralities_Dataframe_'+organism+'.csv', index_col=0)\n",
    "\n",
    "d_deghubs = dict(zip(G.nodes(),df_centralities['degs']))\n",
    "d_clos = dict(zip(G.nodes(), df_centralities['clos']))\n",
    "d_betw = dict(zip(G.nodes(), df_centralities['betw']))\n",
    "d_eigen = dict(zip(G.nodes(), df_centralities['eigen']))\n",
    "\n",
    "# uncomment to set colours\n",
    "colours = color_nodes_from_dict(G, d_clos, color_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 3. Feature Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature based Colouring (all feature associated nodes = coloured , all other = grey)\n",
    "color_method = 'feat-based'\n",
    "\n",
    "graph_nodes_subtracted = []\n",
    "for i in G.nodes():\n",
    "    if int(i) not in feat_graph_overlapping_genes:\n",
    "        graph_nodes_subtracted.append(str(i))\n",
    "\n",
    "feat_graph_overlapping_genes_str = []\n",
    "for i in feat_graph_overlapping_genes:\n",
    "    feat_graph_overlapping_genes_str.append(str(i))\n",
    "\n",
    "    \n",
    "col_feat_genes = color_nodes_same(G, feat_graph_overlapping_genes_str, 'orange')\n",
    "col_nonfeat_genes = color_nodes_same(G, graph_nodes_subtracted, 'grey')\n",
    "\n",
    "colours_unsorted = {**col_feat_genes, **col_nonfeat_genes}\n",
    "colours_sorted = {key:colours_unsorted[key] for key in G.nodes()}\n",
    "\n",
    "# uncomment to set colours\n",
    "colours = list(colours_sorted.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Functional Aij based on following biological Functions:', d_feat_toplist)\n",
    "plt.figure(figsize=(25,25))\n",
    "plt.title(feature+' | UMAP | Metric: '+metric, size=16)\n",
    "\n",
    "nx.draw_networkx_nodes(G, posG_complete_umap_norm, edgecolors = node_edge_color, linewidths = 0.5, node_color=colours, \n",
    "                       node_size = size, \n",
    "                       alpha = opacity_nodes)\n",
    "nx.draw_networkx_edges(G, posG_complete_umap_norm, width = edge_width, edge_color = edge_color, alpha = opacity_edges)\n",
    "plt.box(False)\n",
    "\n",
    "plt.savefig('output_plots/2DPortraitumap_'+feature+'_'+metric+'_'+color_method+str(num_of_features)+'_'+str(n_neighbors)+'_'+str(spread)+'_'+str(min_dist)+'_'+organism+'.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- \n",
    "# UMAP 3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "umap_3D = embed_umap_3D(DM, n_neighbors, spread, min_dist, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posG_3Dumap = get_posG_3D(G.nodes(), umap_3D)\n",
    "posG_3D_complete_umap = {key:posG_3Dumap[key] for key in G.nodes()}\n",
    "\n",
    "# normalize coordinates (for DataDivr Layout input)\n",
    "x_list = []\n",
    "y_list = []\n",
    "z_list = []\n",
    "for k,v in posG_3D_complete_umap.items():\n",
    "    x_list.append(v[0])\n",
    "    y_list.append(v[1])\n",
    "    z_list.append(v[2])\n",
    "    \n",
    "xx_norm = sklearn.preprocessing.minmax_scale(x_list, feature_range=(0, 1), axis=0, copy=True)\n",
    "yy_norm = sklearn.preprocessing.minmax_scale(y_list, feature_range=(0, 1), axis=0, copy=True)\n",
    "zz_norm = sklearn.preprocessing.minmax_scale(z_list, feature_range=(0, 1), axis=0, copy=True)\n",
    "\n",
    "posG_3D_complete_umap_norm = dict(zip(list(G.nodes()), zip(xx_norm,yy_norm,zz_norm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "umap_nodes = get_trace_nodes_3D(posG_3D_complete_umap_norm, l_features, colours, size3d)\n",
    "umap_edges = get_trace_edges_3D(G, posG_3D_complete_umap_norm, edge_colordark, opac=0.05)\n",
    "\n",
    "umap_data = [umap_edges, umap_nodes]\n",
    "#umap_data = [umap_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Neighbours:', n_neighbors)\n",
    "print('Spread:',spread)\n",
    "print('Min. Distance:', min_dist)\n",
    "\n",
    "\n",
    "fig = pgo.Figure()\n",
    "for i in umap_data:\n",
    "    fig.add_trace(i)\n",
    "\n",
    "fig.update_layout(template='plotly_dark', showlegend=False, width=1200, height=1200,\n",
    "                  scene=dict(\n",
    "                      xaxis_title='',\n",
    "                      yaxis_title='',\n",
    "                      zaxis_title='',\n",
    "                      xaxis=dict(nticks=0,tickfont=dict(\n",
    "                            color='black')),\n",
    "                      yaxis=dict(nticks=0,tickfont=dict(\n",
    "                            color='black')),\n",
    "                      zaxis=dict(nticks=0,tickfont=dict(\n",
    "                            color='black')),    \n",
    "                    dragmode=\"turntable\",\n",
    "                    #annotations=annotations,\n",
    "                ))    \n",
    "\n",
    "\n",
    "py.iplot(fig)\n",
    "plotly.offline.plot(fig, filename = 'output_plots/3Dportrait_umap_'+feature+'_'+metric+'_'+color_method+str(num_of_features)+'_'+str(n_neighbors)+'_'+str(spread)+'_'+str(min_dist)+'_'+organism+'.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
